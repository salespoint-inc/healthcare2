{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Azure OpenAI Scenarios for Healthcare\r\n",
        "<hr>\r\n",
        "<hr>\r\n",
        "\r\n",
        "## Disclaimer\r\n",
        "You are interacting with Azure OpenAI Service in this chat. Azure OpenAI Service is NOT a clinical decision support medical device.  All responses are for information and general purpose use only and are not designed, intended or made available for the provision of healthcare services.  Any decisions or clinical actions taken on the basis of this chat are solely your responsibility.\r\n",
        "\r\n",
        "## Inroduction\r\n",
        "\r\n",
        "Azure OpenAI Service can be used in virtually every domain imaginable, and its potential in healthcare is especially remarkable. With Azure OpenAI Service, healthcare professionals can now perform tasks such as summarizing clinical notes, extracting entities from notes, performing cohort analysis, creating safety instructional bots, analyzing call center data, and summarizing research papers - all with unprecedented speed and accuracy.\r\n",
        "\r\n",
        "The following use cases have been defined for healthcare scenario: \r\n",
        "- Summarizing Clinical Notes\r\n",
        "- Extracting Entities from Notes\r\n",
        "- Cohort Analysis\r\n",
        "- Safety Instructional Bot\r\n",
        "- Call Center Analytics\r\n",
        "- Summarizing Medical Journals \r\n",
        "\r\n",
        "## Contents\r\n",
        "\r\n",
        "The demo will be divided into five sections, each having its own sub section\r\n",
        "\r\n",
        "**0. Setting up Notebook**\r\n",
        "\r\n",
        "    0.1 Installation\r\n",
        "\r\n",
        "    0.2 Imports\r\n",
        "\r\n",
        "    0.3 Configuration\r\n",
        "\r\n",
        "    0.4 Brief Description of Model Parameters\r\n",
        "<hr>\r\n",
        "\r\n",
        "**1. Working with clinical notes**\r\n",
        "\r\n",
        "    1.1 Generating Contextual Summary\r\n",
        "\r\n",
        "        1.1.C Code\r\n",
        "\r\n",
        "    1.2 Extracting Entity   \r\n",
        "        \r\n",
        "        1.2.1 Extracting Medication\r\n",
        "\r\n",
        "            1.2.1.C Code\r\n",
        "\r\n",
        "        1.2.2 Extracting Vitals\r\n",
        "\r\n",
        "            1.2.2.C Code\r\n",
        "\r\n",
        "    1.3 Sentiment Analysis\r\n",
        "\r\n",
        "        1.3.C Code\r\n",
        "<hr>\r\n",
        "\r\n",
        "**2. Cohort Analysis**\r\n",
        "\r\n",
        "    2.C Code\r\n",
        "<hr>\r\n",
        "\r\n",
        "**3. Global Occupational Safety**\r\n",
        "\r\n",
        "    3.C Code\r\n",
        "<hr>\r\n",
        "\r\n",
        "**4. Call Center Analytics**\r\n",
        "\r\n",
        "    4.1 Script Improvement\r\n",
        "\r\n",
        "        4.1.C Code\r\n",
        "\r\n",
        "    4.2 Track Issue Resolution and Extract Summary\r\n",
        "\r\n",
        "        4.2.C Code\r\n",
        "<hr>\r\n",
        "\r\n",
        "**5. Summarizing Medical Journals **\r\n",
        "\r\n",
        "    5.C Code\r\n",
        "<hr>"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0 Setting up Notebook"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.1 Installations"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install openai"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: openai in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (0.27.4)\nRequirement already satisfied: requests>=2.20 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from openai) (2.28.2)\nRequirement already satisfied: aiohttp in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from openai) (3.8.3)\nRequirement already satisfied: tqdm in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from openai) (4.65.0)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests>=2.20->openai) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests>=2.20->openai) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests>=2.20->openai) (1.26.14)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests>=2.20->openai) (2.1.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from aiohttp->openai) (1.3.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from aiohttp->openai) (1.3.3)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from aiohttp->openai) (4.0.2)\nRequirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from aiohttp->openai) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from aiohttp->openai) (1.8.2)\nRequirement already satisfied: attrs>=17.3.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from aiohttp->openai) (22.2.0)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.2 Imports"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from openai import cli\r\n",
        "import json\r\n",
        "print(\"Module Importing Successful\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Module Importing Successful\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1681722287832
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.3 Configuration"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load config values\r\n",
        "with open(r'config.json') as config_file:\r\n",
        "    config_details = json.load(config_file)\r\n",
        "\r\n",
        "# Setting up the deployment name\r\n",
        "deployment_name = config_details['COMPLETIONS_MODEL_DV']\r\n",
        "\r\n",
        "# This is set to `azure`\r\n",
        "openai.api_type = \"azure\"\r\n",
        "\r\n",
        "# The API key for your Azure OpenAI resource.\r\n",
        "API_KEY = config_details['OPENAI_API_KEY']\r\n",
        "openai.api_key = os.getenv(API_KEY)\r\n",
        "openai.api_key = API_KEY\r\n",
        "\r\n",
        "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\r\n",
        "openai.api_base = config_details['OPENAI_API_BASE']\r\n",
        "\r\n",
        "# Currently OPENAI API have the following versions available: 2022-12-01\r\n",
        "openai.api_version = config_details['OPENAI_API_VERSION']\r\n",
        "\r\n",
        "ENGINE = config_details['OPENAI_ENGINE_DV']\r\n",
        "\r\n",
        "print(\"configuration complete\")\r\n",
        "print(\"----------------------\")\r\n",
        "print(\"Model      : \" + str(deployment_name))\r\n",
        "print(\"Deployment : \" + str(ENGINE))\r\n",
        "print(\"Endpoint   : \" + str(config_details['OPENAI_API_BASE']))\r\n",
        "print(\"----------------------\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "configuration complete\n----------------------\nModel      : text-davinci-003\nDeployment : text-davinci-003\nEndpoint   : https://chatgpttest45.openai.azure.com/\n----------------------\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1681722288336
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.4 Brief Description of Model Parameters\r\n",
        "\r\n",
        "The parameters we have taken in this are changed and they mean the follows:\r\n",
        "\r\n",
        "1. **prompt** - The trigger text that we to give to the model\r\n",
        "2. **temperature** - The amount of randomness, since we need clear cut answers we have kept it as 0\r\n",
        "3. **max_tokens** - Length of the answer given\r\n",
        "4. **top_p** - distribution of probability of common tokens. 1.0 means \"use all tokens in the vocabulary\" \r\n",
        "5. **frequency_penalty**  and **presence_penalty** - controls the models tendency to use the same predictions, we dont want it to talk about new things so we have kept it as 0"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Working with Clinical Notes"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction\r\n",
        "\r\n",
        "The patient's clinical records document their medical history and must be maintained to include all relevant medical records, progress notes, charts, admission and discharge data, and any other information pertaining to the patient's hospitalization or treatment. This can benefit the patient by reducing the time spent repeating tests, and can benefit healthcare organisations by allowing them to make decisions for a single patient more quickly, freeing up time to spend with those most in need. In this example, a sample of clinical records has been taken, which includes patient demographics, medical history, laboratory test results, medications, imaging studies, vital signs, progress notes, and discharge summaries. This data can be used to identify trends in patient care, track the effectiveness of treatments, and identify potential areas for improvement. It can also be used to develop evidence-based protocols for patient care and improve patient outcomes. Healthcare organisations can use the data from clinical records to provide better care for their patients and improve the overall quality of care.\r\n",
        "\r\n",
        "In this section we will extract the entity and summarise the clinical records."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Generating Contextual Summary"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Brief Description\r\n",
        "\r\n",
        "Text summarization is a technique for automatically creating a short, accurate, and fluent summary of a longer text document. It is used in natural language processing (NLP) to reduce the length of a text by extracting the most important information from it. Text summarization can be done using a variety of algorithms, including natural language processing, semantic analysis, and statistical and machine learning techniques.\r\n",
        "\r\n",
        "Text summarization can be very beneficial in terms of saving time and energy. By summarizing a text, readers can quickly and efficiently get the gist of a document without having to read the entire thing. This can be especially useful for lengthy documents, such as research papers or news articles. Summarization can also be helpful for detecting patterns, such as in text mining or sentiment analysis. Additionally, text summarization can help improve the accuracy of search engines by providing more concise search results.\r\n",
        "\r\n",
        "Generating Contextual summaries help increase patients' recall and comprehension by providing them with relevant and actionable health information to refer to after their visit. Clinical summaries improve patients' quality of care and offer a way for patients and their families to stay informed and engaged."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.1.C. Code"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"\"\"\r\n",
        "# Chief Complaint No complaints.  \r\n",
        "# History of Present Illness Reta is a 30 year-old female (race undeclared). \r\n",
        "Patient has a history of acute bacterial sinusitis (disorder), fatigue (finding), headache (finding), viral sinusitis (disorder), sprain of wrist, \r\n",
        "antepartum eclampsia, suspected covid-19, covid-19, normal pregnancy, fever (finding), sputum finding (finding), blighted ovum, preeclampsia, anemia (disorder), cough (finding), second degree burn, loss of taste (finding).  \r\n",
        "# Social History Patient is single. Patient is an active smoker and is an alcoholic. \r\n",
        "Patient identifies as heterosexual.   Patient comes from a high socioeconomic background.  Patient is a college graduate.  Patient currently has Medicaid.  \r\n",
        "# Allergies  No Known Allergies.  # Medications  natazia 28 day pack; cefuroxime 250 mg oral tablet; seasonique 91 day pack; trinessa 28 day pack; meperidine hydrochloride 50 mg oral tablet; naproxen sodium 220 mg oral tablet;   \r\n",
        "# Assessment and Plan   ## Plan  The following procedures were conducted:  - intramuscular injection The patient was prescribed the following medications:  - 1 ml medroxyprogesterone acetate 150 mg/ml injection   \r\n",
        "# Vital Sign: Vitals recorded for patient at the arrival were Blood Pressure was observed as 117/79 mm[Hg],Body temperature was observed as 35.2 C, Carbon dioxide [Partial pressure] in Blood was observed as 4.7 kPa, Erythrocytes [#/volume] in Blood by Automated count was observed as 4.4 10*12/uL, eye color was observed as blue, Gender identity was observed as Feminism, Glucose [Moles/volume] in Blood was observed as 3.2 mmol/l, Heart rate was observed as 65 /min, Hemoglobin [Mass/volume] in Blood was observed as 8.6 g/dL, Oxygen saturation in Arterial blood by Pulse oximetry was observed as 91%, Second hand smoke exposure was observed as YES.\r\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1681722288877
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarise_text(prompt):\r\n",
        "    len_org = len(prompt.split(\" \"))\r\n",
        "    max_t = int(40/100 * len_org)  \r\n",
        "    instruction = \"perform text summarization \\n\\n: \"\r\n",
        "    prompt = instruction + prompt\r\n",
        "    response = openai.Completion.create(\r\n",
        "        engine=ENGINE,\r\n",
        "        prompt= prompt,\r\n",
        "        temperature=0.9,\r\n",
        "        max_tokens=max_t,\r\n",
        "        top_p=1,\r\n",
        "        frequency_penalty=0,\r\n",
        "        presence_penalty=0,\r\n",
        "        best_of=1,\r\n",
        "        stop=None)\r\n",
        "\r\n",
        "    print(\"original length: \",len_org)\r\n",
        "    \r\n",
        "    res = response['choices'][0]['text']\r\n",
        "\r\n",
        "    print(\"summarized length: \",len(res.split(\" \")))\r\n",
        "    \r\n",
        "    print(res)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1681722289506
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarise_text(text1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "original length:  286\nsummarized length:  48\nPatient has a history of multiple disorders and was given various medications, intramuscular injections, and her vitals were recorded at arrival. There are no known allergies and the patient identifies as feminism, is a college graduate, an active smoker and alcoholic, and is from a high socioeconomic background.\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1681722290300
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Entity Extraction"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Brief Description\r\n",
        "\r\n",
        "Entity extraction is a process of automatically extracting structured information from unstructured text. It is used in natural language processing (NLP) to identify and classify the entities mentioned in a text document. The entities can be people, organizations, locations, products, and so forth. Entity extraction is used in a variety of applications, such as question answering systems, sentiment analysis, and text mining.\r\n",
        "\r\n",
        "Entity extraction can be very beneficial in terms of saving time and energy. By extracting entities from a text, readers can quickly and efficiently get the important information from it. This can be especially useful for lengthy documents, such as research papers or news articles. Entity extraction can also be helpful for detecting patterns, such as in text mining or sentiment analysis. Additionally, entity extraction can help improve the accuracy of search engines by providing more accurate search results."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.1 Extracting Medication\r\n",
        "\r\n",
        "Medication is a medicine or a chemical compound used to treat or cure illness. Medications come in many dosage forms, including tablets, capsules, liquids, creams, and patches. Medication is a substance used to treat, cure, prevent, or diagnose a disease or to enhance physical or mental well-being. It can be a prescription drug, an over-the-counter drug, a herbal remedy, or another type of substance, such as vitamins or supplements."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.2.1.C Code"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_entity_medication(prompt):  \r\n",
        "  instruction = \"perform entity extraction for Medicine Name, Dosage, Duration, Frequency, Route in table format \\n\\n: \"\r\n",
        "  prompt = instruction + prompt\r\n",
        "  response = openai.Completion.create(\r\n",
        "      engine=ENGINE,\r\n",
        "      prompt=prompt,\r\n",
        "      temperature=0,\r\n",
        "      max_tokens=500,\r\n",
        "      top_p=1,\r\n",
        "      frequency_penalty=0,\r\n",
        "      presence_penalty=0,\r\n",
        "      best_of=1,\r\n",
        "      stop=[\"\\n\\n\"],\r\n",
        "  )\r\n",
        "  res = response['choices'][0]['text']\r\n",
        "  print(res)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1681722290815
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extract_entity_medication(text1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nMedicine Name | Dosage | Duration | Frequency | Route \nnatazia 28 day pack | - | 28 days | - | intramuscular injection \ncefuroxime 250 mg oral tablet | 250 mg | - | - | oral \nseasonique 91 day pack | - | 91 days | - | - \ntrinessa 28 day pack | - | 28 days | - | - \nmeperidine hydrochloride 50 mg oral tablet | 50 mg | - | - | oral \nnaproxen sodium 220 mg oral tablet | 220 mg | - | - | oral \nmedroxyprogesterone acetate 150 mg/ml injection | 1 ml | - | - | intramuscular injection\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1681722291521
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.2 Extracting Vitals\r\n",
        "\r\n",
        "Vital are used to measure the body's basic functions. These measurements helps to assess the general physical health of a person which gives clues to possible diseases and show progress toward recovery. The normal ranges for a person's vital signs vary with age, weight, gender and overall health.The four main vital signs are body temperature, blood pressure, pulse (heart rate), and breathing rate.\r\n",
        "\r\n",
        "Vital signs are important indicators of a patient's health and are used to assess the patient's condition and any changes in the patient's condition. They provide important information for making medical decisions, as well as for helping to identify medical emergencies. Vitals are also used to monitor the effectiveness of treatments. By taking and recording vitals regularly, healthcare providers can identify any changes in the patient’s condition and provide timely intervention if necessary."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.2.2.C Code"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_entity_vitals(prompt):  \r\n",
        "  instruction = \"perform entity extraction for Lab test name, lab test result in table format  \\n\\n: \"\r\n",
        "  prompt = instruction + prompt\r\n",
        "  response = openai.Completion.create(\r\n",
        "      engine=ENGINE,\r\n",
        "      prompt=prompt,\r\n",
        "      temperature=1,\r\n",
        "      top_p= 0,\r\n",
        "      max_tokens=1000,\r\n",
        "      best_of=1,\r\n",
        "      stop=None,\r\n",
        "  )\r\n",
        "  res = response['choices'][0]['text']\r\n",
        "  print(res)"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1681722292015
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extract_entity_vitals(text1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nLab Test Name | Lab Test Result \n------------ | ---------------\nBlood Pressure | 117/79 mm[Hg]\nBody temperature | 35.2 C\nCarbon dioxide [Partial pressure] in Blood | 4.7 kPa\nErythrocytes [#/volume] in Blood by Automated count | 4.4 10*12/uL\nGlucose [Moles/volume] in Blood | 3.2 mmol/l\nHeart rate | 65 /min\nHemoglobin [Mass/volume] in Blood | 8.6 g/dL\nOxygen saturation in Arterial blood by Pulse oximetry | 91%\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1681722292723
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Sentiment Analysis"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Brief Description\r\n",
        "\r\n",
        "Sentiment analysis is a process of analyzing a given text or set of texts to determine the underlying sentiment or attitude expressed by the author. It is used to gain an understanding of the attitudes, opinions, and emotions expressed in a text by identifying and extracting relevant keywords and phrases. The goal of sentiment analysis is to determine whether the author expresses a positive, negative, or neutral sentiment.\r\n",
        "\r\n",
        "Sentiment analysis of clinical records is important because it allows healthcare providers to gain insights into a patient’s emotional state and thoughts, which can help inform diagnosis and treatment decisions. It can also help healthcare providers to better understand a patient’s experience and communicate more effectively with them. Furthermore, sentiment analysis can be used to track changes in a patient’s emotional state over time, which can be useful for monitoring the effectiveness of treatments and interventions."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.3.C Code"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment(prompt):  \r\n",
        "  instruction = \"perform sentiment Analysis \\n\\n: \"\r\n",
        "  prompt = instruction + prompt\r\n",
        "  response = openai.Completion.create(\r\n",
        "      engine=ENGINE,\r\n",
        "          prompt= prompt,\r\n",
        "          temperature=0.9,\r\n",
        "          max_tokens=1000,\r\n",
        "          top_p=1,\r\n",
        "          frequency_penalty=0,\r\n",
        "          presence_penalty=0,\r\n",
        "          best_of=1,\r\n",
        "          stop=None,\r\n",
        "  )\r\n",
        "  res = response['choices'][0]['text']\r\n",
        "  print(res)"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1681722293207
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_sentiment(text1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nThe sentiment of this analysis is mostly neutral, though there appears to be some concern for the patient's health due to the presence of various medical issues and lifestyle choices. There does not appear to be any outward judgement or negativity.\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1681722293923
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Cohort Analysis"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction\r\n",
        "\r\n",
        "Cohort analysis is a subset of behavioral analytics that takes the data from a given dataset and groups it into related groups, or cohorts, for the purpose of observational study. This type of analysis is typically used to measure user behavior over time, such as how long it takes users to complete a purchase or how often a customer returns. It can also be used to compare different cohorts, such as those who joined a service at different times or those who have different demographic characteristics.\r\n",
        "\r\n",
        "In this scerio:\r\n",
        "- Given a context, we want the engine to answer based on the question given. The problem with asking the GPT3 models without any context is that it will try to answer even if it does not have answers. This is a problem, and to eliminate it we will fine tune the model prompt."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2.C Code"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"\"\"\r\n",
        "    Question: Hi\r\n",
        "    Hello, How can I help you ! \\n\r\n",
        "\r\n",
        "    Here’s a cohort of all the people who have reported some illness with Contoso Healthcare. Based on the data available in this report, there are a total of 14,195 patients, of which 55% have reported shortness of breath.\r\n",
        "\r\n",
        "    Of these 55% patients who reported shortness of breath, 34.58% are confirmed with the diagnosis, whereas 65.42% have shown atypical symptoms. Most of the patients with confirmed diagnosis belong to Gen X and are between the age group 31-40 years, followed by the age group 51 – 60 years. When ranked based on their city, Miami has reported the highest number of patients with Honolulu at second place, followed by Anchorage, Chicago, and Los Angeles.\r\n",
        "\r\n",
        "    These patients have also reported some other attributes, with Obesity being the most common, being less active as the second and smoking the third. Along with shortness of breath, they have also shown other conditions such as Allergies, Asthma, Bronchitis, and Heart Failure.\r\n",
        "\r\n",
        "    Let’s look at the key influencing factors when the patient is more likely to have a confirmed diagnosis. This patient cohort profile can be decomposed into 6 segments. The first segment of people is 94.9% likely to have confirmed diagnosis because they are Obese, less active, smokers and belong to Gen X, which is within the age group of 31-40 years. Also, if they reside in Miami, a city with poor Air Quality Index, they are more vulnerable to shortness of breath.\r\n",
        "\r\n",
        "    Based on the Air quality Prediction for the next 5 days for Miami, the Providers are recommended to prepare for a 20% increase in regular bed occupancy as more people are likely to be admitted for shortness of breath. It is also advised to send a notification to this cohort in advance so that they can take precautionary measures to avoid health risks.\r\n",
        "\r\n",
        "    A sample communication template might be useful to send a quick push notification to this cohort.\r\n",
        "\r\n",
        "    ALERT: Poor air quality is expected in the next 10 days. Consult your physician for information on precautionary measures you can take to avoid health risks.\\n: \"\"\""
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681722294338
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def PatientCohort_bot(prompt):  \r\n",
        "\r\n",
        "  prompt = instruction + prompt\r\n",
        "  response = openai.Completion.create(\r\n",
        "      engine=ENGINE,\r\n",
        "      prompt=prompt,\r\n",
        "      temperature=0,\r\n",
        "      max_tokens=500,\r\n",
        "      top_p=1,\r\n",
        "      frequency_penalty=0,\r\n",
        "      presence_penalty=0,\r\n",
        "      best_of=1,\r\n",
        "      stop=None)\r\n",
        "  res = response['choices'][0]['text']\r\n",
        "  print(res)"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1681722294772
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = \"What is the recommendation for Providers based on the information from this cohort?\"\r\n",
        "prompt2 = \"Any recommendations for communications to this cohort?\"\r\n",
        "prompt3 = \"Can you share a sample communication letter for this patient?\"\r\n",
        "prompt4 = \"What is recommendation for an Asthama patient aged 60\"\r\n",
        "\r\n",
        "prompt5 = \"What age group does Gen X belong to?\"\r\n",
        "prompt6 = \"What are the other health conditions found in this cohort?\"\r\n",
        "prompt7 = \"What is the most common attribute among these patients?\""
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1681722295206
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt2)\r\n",
        "PatientCohort_bot(prompt2)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Any recommendations for communications to this cohort?\n\n\nYes, it is recommended to send a notification to this cohort in advance so that they can take precautionary measures to avoid health risks. A sample communication template might be useful to send a quick push notification to this cohort. The template should include information about the expected poor air quality, the potential health risks, and the recommended precautionary measures. Additionally, it is important to provide contact information for the patient's physician in case they have any questions or concerns.\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1681722296681
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt3)\r\n",
        "PatientCohort_bot(prompt3)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Can you share a sample communication letter for this patient?\n\n\nDear [Name],\n\nWe are writing to inform you that the air quality in your area is expected to be poor in the next 10 days. Poor air quality can lead to health risks, especially for those with existing conditions such as shortness of breath.\n\nWe recommend that you consult your physician for information on precautionary measures you can take to avoid health risks.\n\nIf you have any questions or concerns, please do not hesitate to contact us.\n\nSincerely,\n\n[Name]\nContoso Healthcare\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1681722298840
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt4)\r\n",
        "PatientCohort_bot(prompt4)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "What is recommendation for an Asthama patient aged 60\n?\n\nFor an asthmatic patient aged 60, it is recommended to take precautionary measures to avoid health risks. This includes avoiding exposure to air pollutants, exercising regularly, and taking medications as prescribed by a physician. Additionally, it is important to monitor symptoms and seek medical attention if necessary.\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1681722299886
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Global Occupational Safety"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Introduction\r\n",
        "\r\n",
        "Global Occupational Safety and Health (GOSH) is the application of safety and health principles, standards, and best practices to protect workers in all parts of the world. It is an international effort to ensure that all workers, regardless of where they live, have access to safe and healthy working conditions. GOSH encompasses a wide range of topics, including workplace safety, hazardous materials, ergonomics, and health promotion.\r\n",
        "\r\n",
        "A bot is a software application that is designed to automate certain tasks. Bots often mimic or simulate human behavior, performing actions such as responding to user input or initiating conversations with other users. A contextual bot is an AI-powered chatbot that uses machine learning and natural language processing to understand the context of a conversation and respond accordingly. Contextual bots are able to learn from conversations over time, allowing them to offer more personalized, relevant, and accurate answers.\r\n",
        "\r\n",
        "In this scenario a bot is being created to help employees with GOSH."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3.C Code"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"\"\"\r\n",
        "    According to the Global Occupational Safety Report of Contoso Healthcare which is\r\n",
        "located in different locations like Anchorage, Chicago, Honolulu, Los Angeles and\r\n",
        "Miami reported 161 Incidents. \r\n",
        "1.In Anchorage the leading source of injury from accidents is fractures followed\r\n",
        "by unspecified injuries, strain, trauma, respiratory symptoms, and allergic\r\n",
        "reactions. The main reason for such injuries is mostly stairs and the number\r\n",
        "of accidents reported there is 32.\r\n",
        "2.In Chicago the leading source of injury from accidents is unspecified followed\r\n",
        "by fractures, hernia, allergic reactions and multiple poisoning, toxic, noxious,\r\n",
        "allergenic effects. The major causes of such injuries are disinfectants,\r\n",
        "vaccines and stairs and the number of accidents reported there is 30.\r\n",
        "3.In Honolulu the leading source of injury from accidents is unspecified injury\r\n",
        "followed by fractures, Bruises, contusions, muscle tears, hernia, and strain.\r\n",
        "The causes of these are indoor stairs and the number of accidents reported\r\n",
        "there is 42.\r\n",
        "4.In Los Angels the leading injuries from accidents is fractures followed by\r\n",
        "hernia, unspecified injuries, allergic reaction, and concussion. The cause of\r\n",
        "these is mainly due to the stairs and the number of accidents reported there is\r\n",
        "29.\r\n",
        "5.In Miami the leading injuries from accidents are fractures followed by\r\n",
        "unspecified injuries, poisoning or allergies. The reason for these accidents is\r\n",
        "stairs, vaccines, smoke, fire gases and n.e.c and the number of accidents\r\n",
        "reported there is 28\r\n",
        "    \"\"\""
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681722300294
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def QA_bot(prompt):  \r\n",
        "    prompt = instruction + prompt\r\n",
        "    response = openai.Completion.create(\r\n",
        "      engine=ENGINE,\r\n",
        "        prompt= prompt,\r\n",
        "        temperature=0.9,\r\n",
        "        max_tokens=1500,\r\n",
        "        top_p=1,\r\n",
        "        frequency_penalty=0,\r\n",
        "        presence_penalty=0,\r\n",
        "        best_of=1,\r\n",
        "        stop=None\r\n",
        "  )\r\n",
        "    res = response['choices'][0]['text']\r\n",
        "    print(res)"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1681722300750
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = \"What is the leading cause of injuries in Miami?\"\r\n",
        "prompt2 = \"What is the leading injury in Chicago?\"\r\n",
        "prompt3 = \"How many hospitals are there in Anchorage?\"\r\n",
        "prompt4 = \"What is the second highest injury in Chicago?\"\r\n",
        "prompt5 = \"Which city reports the highest number of accidents?\""
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1681722301167
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt1)\r\n",
        "QA_bot(prompt1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "What is the leading cause of injuries in Miami?\n\n\nThe leading cause of injuries in Miami is stairs.\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1681722301587
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt5)\r\n",
        "QA_bot(prompt5)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Which city reports the highest number of accidents?\n\n\nThe city that reports the highest number of accidents is Honolulu with a total of 42 accidents reported.\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1681722302014
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Call Centre Analytics"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction\r\n",
        "\r\n",
        "Call center analytics is the process of using data and technology to analyze the performance of a call center. It helps organizations optimize operations, improve customer experience, and increase revenue. Call center analytics can be used to analyze customer interactions, such as call volume, length of calls, customer satisfaction ratings, and customer feedback. It can also be used to identify trends and opportunities, such as increasing call volumes or identifying areas of improvement in customer service. By leveraging call center analytics, organizations can ensure that their customer service teams are performing at their best and that customers are receiving the best possible experience.\r\n",
        "\r\n",
        " It is also used to identify trends and opportunities, such as increasing call volumes or customer service areas that need improvement. With call center analytics, organizations can ensure that their customer service teams are performing at their best and that customers are receiving the best possible experience. The analytics also provide valuable insights on customer behavior and preferences that can be used to customize services and improve customer loyalty."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transcript\r\n",
        "\r\n",
        "A transcript in a call center is a written record of a customer's support experience. It documents all the customer's interactions with customer service agents, such as their questions, concerns, and comments A transcript typically includes the customer's name, contact details, and other pertinent information. Call center transcripts are important for providing customer service agents with the appropriate context to address a customer’s needs. They can also be used to monitor customer service performance and identify areas for improvement."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 4.C Code"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transcript = \"\"\"\r\n",
        "Hospital staff: Good morning, this is the hospital. How may I help you?\r\n",
        "Patient: Yes, I am having some medical issues and was wondering if I could come in to get checked out.\r\n",
        "Hospital staff: Certainly. What are the symptoms you are experiencing?\r\n",
        "Patient: I have a fever, aches and chills, and a sore throat.\r\n",
        "Hospital staff: Okay, it sounds like you may have the flu. We can schedule you in to see a doctor if you’d like.\r\n",
        "Patient: That would be great. What time would be best for me to come in?\r\n",
        "Hospital staff: We have an opening at 1 pm this afternoon. Would that work for you?\r\n",
        "Patient: Yes, that would be perfect.\r\n",
        "Hospital staff: Alright, I will go ahead and book that appointment for you. Please arrive about 15 minutes before your appointment so the receptionist can get you checked in.\r\n",
        "Patient: Got it. Can I bring someone with me to the appointment?\r\n",
        "Hospital staff: Yes, you can bring a friend or family member with you.\r\n",
        "Patient: Alright, thank you.\r\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1681722302446
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Script Improvement\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Brief Description\r\n",
        "\r\n",
        "Transcript improvement is a process of making transcripts of audio or video recordings more accurate and easier to read. This process can involve a variety of techniques, such as automatic speech recognition, editing and formatting of text, and audio and video synchronization. The goal of transcript improvement is to produce a document that accurately reflects the original recording in a way that is easy for readers to understand. This can help to improve the accuracy of audio and video recordings, as well as make them easier to use in court proceedings and other legal proceedings."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 4.1.C Code"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instruction =\"improve the above transcript:\"\r\n",
        "def transcript_betterment(prompt,instruction):\r\n",
        "    prompt = prompt + instruction\r\n",
        "    response = openai.Completion.create(\r\n",
        "      engine=ENGINE,\r\n",
        "        prompt= prompt,\r\n",
        "        temperature=0.9,\r\n",
        "        max_tokens=2500,\r\n",
        "        top_p=1,\r\n",
        "        frequency_penalty=0,\r\n",
        "        presence_penalty=0,\r\n",
        "        best_of=1,\r\n",
        "        stop=None\r\n",
        "  )\r\n",
        "    res = response['choices'][0]['text']\r\n",
        "    print(res)\r\n",
        "    \r\n",
        "transcript_betterment(transcript,instruction)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n\nHospital staff: Good morning, this is the hospital. How may I help you?\nPatient: Yes, I am having some medical issues and was wondering if I could come in to get checked out.\nHospital staff: Certainly. What are the symptoms you are experiencing?\nPatient: I have a fever, aches and chills, and a sore throat.\nHospital staff: Okay, it sounds like you may have the flu. We can schedule you in to see a doctor if you’d like. When would be the best time for you?\nPatient: This afternoon would be great.\nHospital staff: We have an opening at 1 pm this afternoon. Would that work for you?\nPatient: Yes, that would be perfect.\nHospital staff: Alright, I will go ahead and book that appointment for you. Please arrive about 15 minutes before your appointment so the receptionist can get you checked in. Is there anything else I can help you with today?\nPatient: Yes, can I bring someone with me to the appointment?\nHospital staff: Yes, you can bring a friend or family member with you.\nPatient: Alright, thank you.\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1681722304757
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Track Issue Resolution and Extract Summary"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Brief Description\r\n",
        "\r\n",
        "**Issue Resolution**\r\n",
        "\r\n",
        "Issue resolution for a call center is the process of resolving customer complaints and inquiries. This involves listening to the customer, understanding their needs, and providing solutions that meet their expectations. It requires both technical expertise and interpersonal skills. The goal of issue resolution is to ensure customer satisfaction and loyalty, as well as to improve customer experience.\r\n",
        "\r\n",
        "Issue resolution for a call center requires representatives to be knowledgeable about the company's products and services, be able to accurately assess customer needs, and be patient and understanding when addressing customer complaints. They must also be able to effectively listen to customers and provide them with clear explanations and solutions. Representatives should also be able to accurately document customer complaints and inquiries and provide feedback to the customer. Finally, representatives should be able to provide follow-up support and ensure that the customer's experience has been satisfactory.\r\n",
        "\r\n",
        "**Summarization of Transcript**\r\n",
        "\r\n",
        "Summarization of a call transcript is the process of taking a long, detailed conversation and condensing it into a shorter, more concise summary. This summary can be useful for businesses that need to quickly and easily recall the main points of a conversation or to provide a brief overview of a conversation for future reference. The benefit of summarizing a call transcript is that it can provide a quick, easily digestible snapshot of the key points of a conversation, saving time and resources.\r\n",
        "Summarizing a call transcript involves taking a long, detailed conversation and turning it into a shorter, more concise summary. This summary should cover the main points of the conversation, including any key decisions that were made and any important information that was exchanged. The summarization should also include any action items that were agreed upon and any follow-up steps that need to be taken. By creating a concise summary, businesses can quickly and easily recall the main points of a conversation and have a brief overview of a conversation for future reference. This can save time and resources when reviewing calls and can help to ensure that important points are not forgotten."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 4.2.C Code"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_resolution(text):\r\n",
        "    add_text = \"\"\"Generate a summary of the below given conversation in the following format:\r\n",
        "                  Customer problem:\r\n",
        "                  Outcome of the conversation:\r\n",
        "                  Action items for follow-up::\r\n",
        "                  Medication Given (if any):\r\n",
        "                  Summary of Call:\\n\"\"\"\r\n",
        "    prompt = add_text + '\\n' + text + '\\n' + 'Summary:' + '\\n'\r\n",
        "    response = openai.Completion.create(\r\n",
        "      engine=ENGINE,\r\n",
        "        prompt= prompt,\r\n",
        "        temperature=0.7,\r\n",
        "        max_tokens=1500,\r\n",
        "        top_p=1,\r\n",
        "        frequency_penalty=0,\r\n",
        "        presence_penalty=0,\r\n",
        "        best_of=1,\r\n",
        "        stop=None\r\n",
        "  )\r\n",
        "    res = response['choices'][0]['text']\r\n",
        "    print(res)"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1681722305223
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_resolution(transcript)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Customer problem: Patient is experiencing a fever, aches, chills, and a sore throat.\nOutcome of the conversation: Patient is scheduled for an appointment at 1 pm this afternoon.\nAction items for follow-up: Patient to arrive 15 minutes before the appointment. Patient can bring a friend or family member to the appointment.\nMedication Given (if any): None.\nSummary of Call: Patient is scheduled for an appointment at 1 pm this afternoon. The patient was advised to arrive 15 minutes prior to the appointment, and can bring a friend or family member with them.\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1681722307196
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Summarizing Medical Journals "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction\r\n",
        "\r\n",
        "Medical Journals summarization is the process of condensing a journal into a shorter, more concise form. This is often done by removing unnecessary details, shortening long passages, and eliminating irrelevant content. The goal of summarization is to present the main points of the paper in a way that is easily understood.\r\n",
        "\r\n",
        "The benefit of summarizing a journal is that it allows readers to quickly understand the main points and figures of the journal without having to read the entire document. This saves time and allows readers to focus on the most important parts of the research. Summarization also allows readers to quickly determine if the paper is relevant to their interests or if they should move on and read other papers. Summarizing a journal can also help the reader better understand the journal's arguments and points and can provide a quick reference to the journal's main ideas."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 5.C Code"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_summary(corpus):\r\n",
        "    import nltk\r\n",
        "    nltk.download('punkt')\r\n",
        "    from nltk.tokenize import sent_tokenize\r\n",
        "\r\n",
        "    def split_text_into_paragraphs(text):\r\n",
        "        # Split the text into sentences.\r\n",
        "        sentences = sent_tokenize(text)\r\n",
        "        # Split the sentences into small paragraphs of around 10000 tokens each.\r\n",
        "        paragraphs = {}\r\n",
        "        current_paragraph = ''\r\n",
        "        current_length = 0\r\n",
        "        current_key = 1\r\n",
        "        for sentence in sentences:\r\n",
        "            # If adding the current sentence to the current paragraph exceeds the target length,\r\n",
        "            # add the current paragraph to the dictionary of paragraphs and start a new paragraph.\r\n",
        "            if current_length + len(sentence) + 1 > 10000:\r\n",
        "                while current_paragraph[-1] not in ['.', '!', '?']:\r\n",
        "                    current_paragraph = current_paragraph.rsplit(' ', 1)[0]\r\n",
        "                paragraphs[f'para{current_key}'] = current_paragraph.strip()\r\n",
        "                current_paragraph = ''\r\n",
        "                current_length = 0\r\n",
        "                current_key += 1\r\n",
        "            # Add the current sentence to the current paragraph.\r\n",
        "            current_paragraph += sentence + ' '\r\n",
        "            current_length += len(sentence) + 1\r\n",
        "        # Add the last paragraph to the dictionary of paragraphs.\r\n",
        "        while current_paragraph[-1] not in ['.', '!', '?']:\r\n",
        "            current_paragraph = current_paragraph.rsplit(' ', 1)[0]\r\n",
        "        paragraphs[f'para{current_key}'] = current_paragraph.strip()\r\n",
        "        \r\n",
        "        return paragraphs\r\n",
        "\r\n",
        "    def summarise_text(corpus):\r\n",
        "        len_org = len(corpus.split(\" \"))\r\n",
        "        max_t = int(40/100 * len_org)  \r\n",
        "        instruction = \"Generate Summary in third person: \"\r\n",
        "        prompt = instruction + corpus\r\n",
        "        response = openai.Completion.create(\r\n",
        "            engine=ENGINE,\r\n",
        "            prompt= prompt,\r\n",
        "            temperature=0.9,\r\n",
        "            max_tokens=max_t,\r\n",
        "            top_p=1,\r\n",
        "            frequency_penalty=0,\r\n",
        "            presence_penalty=0,\r\n",
        "            best_of=1,\r\n",
        "            stop=None)  \r\n",
        "        res = response['choices'][0]['text']\r\n",
        "        return res\r\n",
        "\r\n",
        "\r\n",
        "    def summarise_universal_text(corpus):\r\n",
        "        instruction = \"Generate high level summary from following text:\"\r\n",
        "        prompt = instruction + corpus\r\n",
        "        response = openai.Completion.create(\r\n",
        "            engine=ENGINE,\r\n",
        "            prompt= prompt,\r\n",
        "            temperature=0.9,\r\n",
        "            max_tokens=1000,\r\n",
        "            top_p=1,\r\n",
        "            frequency_penalty=0,\r\n",
        "            presence_penalty=0,\r\n",
        "            best_of=1,\r\n",
        "            stop=None)  \r\n",
        "        res = response['choices'][0]['text']\r\n",
        "        return res\r\n",
        "    \r\n",
        "    paragraphs = split_text_into_paragraphs(corpus)\r\n",
        "    print(\"Paragraphs Divided\")\r\n",
        "    universal_summary = []\r\n",
        "    for para in paragraphs:\r\n",
        "        individual_summary = summarise_text(paragraphs[para])\r\n",
        "        universal_summary.append(individual_summary)\r\n",
        "\r\n",
        "    txt = \"\"\r\n",
        "    for summary in universal_summary:\r\n",
        "        txt = txt + summary\r\n",
        "\r\n",
        "    txt =  txt.replace('\\n', '')\r\n",
        "    print(\"Summary:\")\r\n",
        "    us = summarise_universal_text(txt)\r\n",
        "    print(us)\r\n",
        "    return paragraphs,txt\r\n"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1681722307642
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\r\n",
        "End of Document\r\n",
        "<hr>"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_ignore_dictionary": [
          "customer’s",
          "summarization"
        ],
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}