{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hospital Wait Time Forecast\n",
        "\n",
        "In this notebook we use Azure AutoML to forecast the average wait time of patients in each city"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "$*****$ Important – Do not use in production, for demonstration purposes only – please review the legal notices before continuing $*****$ "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Legal Notices \n",
        "\n",
        "This presentation, demonstration, and demonstration model are for informational purposes only. Microsoft makes no warranties, express or implied, in this presentation demonstration, and demonstration model. Nothing in this presentation, demonstration, or demonstration model modifies any of the terms and conditions of Microsoft’s written and signed agreements. This is not an offer and applicable terms and the information provided is subject to revision and may be changed at any time by Microsoft.\n",
        "\n",
        "This presentation, demonstration, and/or demonstration model do not give you or your organization any license to any patents, trademarks, copyrights, or other intellectual property covering the subject matter in this presentation, demonstration, and demonstration model.\n",
        "\n",
        "The information contained in this presentation, demonstration and demonstration model represent the current view of Microsoft on the issues discussed as of the date of presentation and/or demonstration, and the duration of your access to the demonstration model. Because Microsoft must respond to changing market conditions, it should not be interpreted to be a commitment on the part of Microsoft, and Microsoft cannot guarantee the accuracy of any information presented after the date of presentation and/or demonstration and for the duration of your access to the demonstration model.\n",
        "\n",
        "No Microsoft technology, nor any of its component technologies, including the demonstration model, is intended or made available: (1) as a medical device; (2) for the diagnosis of disease or other conditions, or in the cure, mitigation, treatment or prevention of a disease or other conditions; or (3) as a substitute for the professional clinical advice, opinion, or judgment of a treating healthcare professional. Partners or customers are responsible for ensuring the regulatory compliance of any solution they build using Microsoft technologies.\n",
        "\n",
        "© 2020 Microsoft Corporation. All rights reserved"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up the workspace"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "import pandas as pd\n",
        "import azureml.core\n",
        "from azureml.core import Workspace, Datastore, Dataset, Experiment\n",
        "from azureml.data import DataType\n",
        "from azureml.data.datapath import DataPath\n",
        "from azureml.core.compute import AmlCompute\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.train.automl.run import AutoMLRun\n",
        "import os\n",
        "\n",
        "print(\"SDK Version:\", azureml.core.VERSION)\n",
        "\n",
        "from azureml.core import Workspace, Datastore, Dataset\n",
        "ws = Workspace.from_config()\n",
        "ws"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SDK Version: 1.48.0\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "Workspace.create(name='mlw-healthcare2-prod', subscription_id='506e86fc-853c-4557-a6e5-ad72114efd2b', resource_group='rg-healthcare2-prod')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1680785902870
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create new datastore for Datasets"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import GlobalVariables"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1680785903175
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Datastore\n",
        "\n",
        "blob_datastore_name=GlobalVariables.WAIT_TIME_DATASTORE_NAME # Name of the datastore in workspace \n",
        "container_name=GlobalVariables.GLOBAL_CONTAINER_NAME\n",
        "account_name=GlobalVariables.STORAGE_ACCOUNT_NAME\n",
        "account_key=GlobalVariables.STORAGE_ACCOUNT_KEY # Storage account access key\n",
        "\n",
        "blob_datastore = Datastore.register_azure_blob_container(workspace=ws, \n",
        "                                                         datastore_name=blob_datastore_name, \n",
        "                                                         container_name=container_name, \n",
        "                                                         account_name=account_name,\n",
        "                                                         account_key=account_key)\n",
        "\n",
        "dstore = Datastore.get(ws, datastore_name=blob_datastore_name)\n",
        "dstore"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "{\n  \"name\": \"wait_time_prediction_store\",\n  \"container_name\": \"predictiveanalytics\",\n  \"account_name\": \"sthealthcare2prod\",\n  \"protocol\": \"https\",\n  \"endpoint\": \"core.windows.net\"\n}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1680785903632
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data.datapath import DataPath\n",
        "filepath = GlobalVariables.WAIT_TIME_INPUT_FILE_NAME\n",
        "print(filepath)\n",
        "\n",
        "# Set the path to the storage account containing the file\n",
        "datastore_path = [DataPath(dstore, filepath)]\n",
        "patientdataset = Dataset.Tabular.from_delimited_files(path=datastore_path)\n",
        "patientdataset.take(5).to_pandas_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/pbiPatientPredictiveSet.csv\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "   encounter_id  hospital_id  department_id         city  \\\n0         21059            1              1  Los Angeles   \n1       2305342            2              6      Chicago   \n2        426911            1              1  Los Angeles   \n3        797146            1              2  Los Angeles   \n4       2847178           21              7        Miami   \n\n                             patient_id  patient_age  risk_level acute_type  \\\n0  738311d9-2f2c-11eb-aa27-70b5e8b8edbb           61           5      Acute   \n1  0e930c2e-2f31-11eb-8d13-70b5e8b8edbb           59           2  Non Acute   \n2  c7ae99aa-2f2c-11eb-88b4-70b5e8b8edbb           79           1  Non Acute   \n3  4a63175e-2f2d-11eb-bf71-70b5e8b8edbb           14           2  Non Acute   \n4  79430da9-2f32-11eb-87ff-70b5e8b8edbb           50           4      Acute   \n\n  patient_category  doctor_id  ...  drug_cost  hospital_expense follow_up  \\\n0        InPatient       9542  ...        840              6300         0   \n1        InPatient       3127  ...        754              6074         0   \n2        InPatient       7261  ...       1017              7037         0   \n3        InPatient      11029  ...        691              6069         0   \n4        InPatient      12480  ...        751              5659         1   \n\n   readmitted_patient       payment_type                date  month  year  \\\n0                   0           Medicaid 2016-06-28 17:46:00    Jun  2016   \n1                   0           Medicaid 2019-06-18 20:47:00    Jun  2019   \n2                   0  Private Insurance 2017-08-10 23:47:00    Aug  2017   \n3                   0           Medicare 2019-11-04 02:59:00    Nov  2019   \n4                   0  Private Insurance 2016-06-11 17:28:00    Jun  2016   \n\n   disease reason_for_readmission  \n0     None           radiotherapy  \n1     None              alzheimer  \n2     None           radiotherapy  \n3     None              scoliosis  \n4     None                    flu  \n\n[5 rows x 25 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>encounter_id</th>\n      <th>hospital_id</th>\n      <th>department_id</th>\n      <th>city</th>\n      <th>patient_id</th>\n      <th>patient_age</th>\n      <th>risk_level</th>\n      <th>acute_type</th>\n      <th>patient_category</th>\n      <th>doctor_id</th>\n      <th>...</th>\n      <th>drug_cost</th>\n      <th>hospital_expense</th>\n      <th>follow_up</th>\n      <th>readmitted_patient</th>\n      <th>payment_type</th>\n      <th>date</th>\n      <th>month</th>\n      <th>year</th>\n      <th>disease</th>\n      <th>reason_for_readmission</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21059</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Los Angeles</td>\n      <td>738311d9-2f2c-11eb-aa27-70b5e8b8edbb</td>\n      <td>61</td>\n      <td>5</td>\n      <td>Acute</td>\n      <td>InPatient</td>\n      <td>9542</td>\n      <td>...</td>\n      <td>840</td>\n      <td>6300</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Medicaid</td>\n      <td>2016-06-28 17:46:00</td>\n      <td>Jun</td>\n      <td>2016</td>\n      <td>None</td>\n      <td>radiotherapy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2305342</td>\n      <td>2</td>\n      <td>6</td>\n      <td>Chicago</td>\n      <td>0e930c2e-2f31-11eb-8d13-70b5e8b8edbb</td>\n      <td>59</td>\n      <td>2</td>\n      <td>Non Acute</td>\n      <td>InPatient</td>\n      <td>3127</td>\n      <td>...</td>\n      <td>754</td>\n      <td>6074</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Medicaid</td>\n      <td>2019-06-18 20:47:00</td>\n      <td>Jun</td>\n      <td>2019</td>\n      <td>None</td>\n      <td>alzheimer</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>426911</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Los Angeles</td>\n      <td>c7ae99aa-2f2c-11eb-88b4-70b5e8b8edbb</td>\n      <td>79</td>\n      <td>1</td>\n      <td>Non Acute</td>\n      <td>InPatient</td>\n      <td>7261</td>\n      <td>...</td>\n      <td>1017</td>\n      <td>7037</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Private Insurance</td>\n      <td>2017-08-10 23:47:00</td>\n      <td>Aug</td>\n      <td>2017</td>\n      <td>None</td>\n      <td>radiotherapy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>797146</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Los Angeles</td>\n      <td>4a63175e-2f2d-11eb-bf71-70b5e8b8edbb</td>\n      <td>14</td>\n      <td>2</td>\n      <td>Non Acute</td>\n      <td>InPatient</td>\n      <td>11029</td>\n      <td>...</td>\n      <td>691</td>\n      <td>6069</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Medicare</td>\n      <td>2019-11-04 02:59:00</td>\n      <td>Nov</td>\n      <td>2019</td>\n      <td>None</td>\n      <td>scoliosis</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2847178</td>\n      <td>21</td>\n      <td>7</td>\n      <td>Miami</td>\n      <td>79430da9-2f32-11eb-87ff-70b5e8b8edbb</td>\n      <td>50</td>\n      <td>4</td>\n      <td>Acute</td>\n      <td>InPatient</td>\n      <td>12480</td>\n      <td>...</td>\n      <td>751</td>\n      <td>5659</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Private Insurance</td>\n      <td>2016-06-11 17:28:00</td>\n      <td>Jun</td>\n      <td>2016</td>\n      <td>None</td>\n      <td>flu</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1680785907166
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Convert to Pandas DataFrame to do data preparation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "patient_df = patientdataset.to_pandas_dataframe()\n",
        "patient_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "   encounter_id  hospital_id  department_id         city  \\\n0         21059            1              1  Los Angeles   \n1       2305342            2              6      Chicago   \n2        426911            1              1  Los Angeles   \n3        797146            1              2  Los Angeles   \n4       2847178           21              7        Miami   \n\n                             patient_id  patient_age  risk_level acute_type  \\\n0  738311d9-2f2c-11eb-aa27-70b5e8b8edbb           61           5      Acute   \n1  0e930c2e-2f31-11eb-8d13-70b5e8b8edbb           59           2  Non Acute   \n2  c7ae99aa-2f2c-11eb-88b4-70b5e8b8edbb           79           1  Non Acute   \n3  4a63175e-2f2d-11eb-bf71-70b5e8b8edbb           14           2  Non Acute   \n4  79430da9-2f32-11eb-87ff-70b5e8b8edbb           50           4      Acute   \n\n  patient_category  doctor_id  ...  drug_cost  hospital_expense follow_up  \\\n0        InPatient       9542  ...        840              6300         0   \n1        InPatient       3127  ...        754              6074         0   \n2        InPatient       7261  ...       1017              7037         0   \n3        InPatient      11029  ...        691              6069         0   \n4        InPatient      12480  ...        751              5659         1   \n\n   readmitted_patient       payment_type                date  month  year  \\\n0                   0           Medicaid 2016-06-28 17:46:00    Jun  2016   \n1                   0           Medicaid 2019-06-18 20:47:00    Jun  2019   \n2                   0  Private Insurance 2017-08-10 23:47:00    Aug  2017   \n3                   0           Medicare 2019-11-04 02:59:00    Nov  2019   \n4                   0  Private Insurance 2016-06-11 17:28:00    Jun  2016   \n\n   disease reason_for_readmission  \n0     None           radiotherapy  \n1     None              alzheimer  \n2     None           radiotherapy  \n3     None              scoliosis  \n4     None                    flu  \n\n[5 rows x 25 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>encounter_id</th>\n      <th>hospital_id</th>\n      <th>department_id</th>\n      <th>city</th>\n      <th>patient_id</th>\n      <th>patient_age</th>\n      <th>risk_level</th>\n      <th>acute_type</th>\n      <th>patient_category</th>\n      <th>doctor_id</th>\n      <th>...</th>\n      <th>drug_cost</th>\n      <th>hospital_expense</th>\n      <th>follow_up</th>\n      <th>readmitted_patient</th>\n      <th>payment_type</th>\n      <th>date</th>\n      <th>month</th>\n      <th>year</th>\n      <th>disease</th>\n      <th>reason_for_readmission</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21059</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Los Angeles</td>\n      <td>738311d9-2f2c-11eb-aa27-70b5e8b8edbb</td>\n      <td>61</td>\n      <td>5</td>\n      <td>Acute</td>\n      <td>InPatient</td>\n      <td>9542</td>\n      <td>...</td>\n      <td>840</td>\n      <td>6300</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Medicaid</td>\n      <td>2016-06-28 17:46:00</td>\n      <td>Jun</td>\n      <td>2016</td>\n      <td>None</td>\n      <td>radiotherapy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2305342</td>\n      <td>2</td>\n      <td>6</td>\n      <td>Chicago</td>\n      <td>0e930c2e-2f31-11eb-8d13-70b5e8b8edbb</td>\n      <td>59</td>\n      <td>2</td>\n      <td>Non Acute</td>\n      <td>InPatient</td>\n      <td>3127</td>\n      <td>...</td>\n      <td>754</td>\n      <td>6074</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Medicaid</td>\n      <td>2019-06-18 20:47:00</td>\n      <td>Jun</td>\n      <td>2019</td>\n      <td>None</td>\n      <td>alzheimer</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>426911</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Los Angeles</td>\n      <td>c7ae99aa-2f2c-11eb-88b4-70b5e8b8edbb</td>\n      <td>79</td>\n      <td>1</td>\n      <td>Non Acute</td>\n      <td>InPatient</td>\n      <td>7261</td>\n      <td>...</td>\n      <td>1017</td>\n      <td>7037</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Private Insurance</td>\n      <td>2017-08-10 23:47:00</td>\n      <td>Aug</td>\n      <td>2017</td>\n      <td>None</td>\n      <td>radiotherapy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>797146</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Los Angeles</td>\n      <td>4a63175e-2f2d-11eb-bf71-70b5e8b8edbb</td>\n      <td>14</td>\n      <td>2</td>\n      <td>Non Acute</td>\n      <td>InPatient</td>\n      <td>11029</td>\n      <td>...</td>\n      <td>691</td>\n      <td>6069</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Medicare</td>\n      <td>2019-11-04 02:59:00</td>\n      <td>Nov</td>\n      <td>2019</td>\n      <td>None</td>\n      <td>scoliosis</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2847178</td>\n      <td>21</td>\n      <td>7</td>\n      <td>Miami</td>\n      <td>79430da9-2f32-11eb-87ff-70b5e8b8edbb</td>\n      <td>50</td>\n      <td>4</td>\n      <td>Acute</td>\n      <td>InPatient</td>\n      <td>12480</td>\n      <td>...</td>\n      <td>751</td>\n      <td>5659</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Private Insurance</td>\n      <td>2016-06-11 17:28:00</td>\n      <td>Jun</td>\n      <td>2016</td>\n      <td>None</td>\n      <td>flu</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1680785915241
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View info to see what the column names and types are\n",
        "patient_df.info()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4369400 entries, 0 to 4369399\nData columns (total 25 columns):\n #   Column                  Dtype         \n---  ------                  -----         \n 0   encounter_id            int64         \n 1   hospital_id             int64         \n 2   department_id           int64         \n 3   city                    object        \n 4   patient_id              object        \n 5   patient_age             int64         \n 6   risk_level              int64         \n 7   acute_type              object        \n 8   patient_category        object        \n 9   doctor_id               int64         \n 10  length_of_stay          int64         \n 11  wait_time               int64         \n 12  type_of_stay            object        \n 13  treatment_cost          int64         \n 14  claim_cost              int64         \n 15  drug_cost               int64         \n 16  hospital_expense        int64         \n 17  follow_up               int64         \n 18  readmitted_patient      int64         \n 19  payment_type            object        \n 20  date                    datetime64[ns]\n 21  month                   object        \n 22  year                    int64         \n 23  disease                 object        \n 24  reason_for_readmission  object        \ndtypes: datetime64[ns](1), int64(15), object(9)\nmemory usage: 833.4+ MB\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1680785915545
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation for AutoML"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "timeseries_df = patient_df[['city','date', 'wait_time']]\n",
        "timeseries_df"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "                city                date  wait_time\n0        Los Angeles 2016-06-28 17:46:00         31\n1            Chicago 2019-06-18 20:47:00         38\n2        Los Angeles 2017-08-10 23:47:00         35\n3        Los Angeles 2019-11-04 02:59:00         42\n4              Miami 2016-06-11 17:28:00         50\n...              ...                 ...        ...\n4369395        Miami 2018-11-11 20:06:00         41\n4369396        Miami 2018-11-14 15:48:00         44\n4369397        Miami 2018-11-07 05:06:00         43\n4369398        Miami 2018-11-02 07:03:00         44\n4369399        Miami 2018-11-09 20:14:00         43\n\n[4369400 rows x 3 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city</th>\n      <th>date</th>\n      <th>wait_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Los Angeles</td>\n      <td>2016-06-28 17:46:00</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Chicago</td>\n      <td>2019-06-18 20:47:00</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Los Angeles</td>\n      <td>2017-08-10 23:47:00</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Los Angeles</td>\n      <td>2019-11-04 02:59:00</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Miami</td>\n      <td>2016-06-11 17:28:00</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4369395</th>\n      <td>Miami</td>\n      <td>2018-11-11 20:06:00</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>4369396</th>\n      <td>Miami</td>\n      <td>2018-11-14 15:48:00</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>4369397</th>\n      <td>Miami</td>\n      <td>2018-11-07 05:06:00</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>4369398</th>\n      <td>Miami</td>\n      <td>2018-11-02 07:03:00</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>4369399</th>\n      <td>Miami</td>\n      <td>2018-11-09 20:14:00</td>\n      <td>43</td>\n    </tr>\n  </tbody>\n</table>\n<p>4369400 rows × 3 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1680785915877
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Remove time dimension from the date column"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "timeseries_df['date'] = pd.to_datetime(timeseries_df['date'].dt.date)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_50926/3870217496.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  timeseries_df['date'] = pd.to_datetime(timeseries_df['date'].dt.date)\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1680785917167
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "timeseries_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "          city       date  wait_time\n0  Los Angeles 2016-06-28         31\n1      Chicago 2019-06-18         38\n2  Los Angeles 2017-08-10         35\n3  Los Angeles 2019-11-04         42\n4        Miami 2016-06-11         50",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city</th>\n      <th>date</th>\n      <th>wait_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Los Angeles</td>\n      <td>2016-06-28</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Chicago</td>\n      <td>2019-06-18</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Los Angeles</td>\n      <td>2017-08-10</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Los Angeles</td>\n      <td>2019-11-04</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Miami</td>\n      <td>2016-06-11</td>\n      <td>50</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "scrolled": true,
        "gather": {
          "logged": 1680785917567
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "timeseries_df.info()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4369400 entries, 0 to 4369399\nData columns (total 3 columns):\n #   Column     Dtype         \n---  ------     -----         \n 0   city       object        \n 1   date       datetime64[ns]\n 2   wait_time  int64         \ndtypes: datetime64[ns](1), int64(1), object(1)\nmemory usage: 100.0+ MB\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1680785917876
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "timeseries_df_grouped = timeseries_df.groupby(['city','date'])['wait_time'].mean().reset_index()\n",
        "timeseries_df_grouped = timeseries_df_grouped.sort_values(['city','date']).reset_index(drop=True)\n",
        "timeseries_df_grouped.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "        city       date  wait_time\n0  Anchorage 2015-12-17  37.000000\n1  Anchorage 2015-12-18  46.500000\n2  Anchorage 2015-12-19  41.666667\n3  Anchorage 2015-12-20  39.000000\n4  Anchorage 2015-12-21  43.000000",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city</th>\n      <th>date</th>\n      <th>wait_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Anchorage</td>\n      <td>2015-12-17</td>\n      <td>37.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Anchorage</td>\n      <td>2015-12-18</td>\n      <td>46.500000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Anchorage</td>\n      <td>2015-12-19</td>\n      <td>41.666667</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Anchorage</td>\n      <td>2015-12-20</td>\n      <td>39.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Anchorage</td>\n      <td>2015-12-21</td>\n      <td>43.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1680785918242
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Data based on Cities"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "city_wise_dfs = {}\n",
        "\n",
        "cities = list(timeseries_df_grouped['city'].unique())\n",
        "for city in cities:\n",
        "    city_df = timeseries_df_grouped[timeseries_df_grouped['city'] == city]\n",
        "    city_wise_dfs[city] = city_df[['date', 'wait_time']]\n",
        "    \n",
        "city_wise_dfs['Honolulu'].head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "           date  wait_time\n3618 2015-12-16  36.000000\n3619 2015-12-17  39.250000\n3620 2015-12-18  45.000000\n3621 2015-12-19  37.727273\n3622 2015-12-20  40.666667",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>wait_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3618</th>\n      <td>2015-12-16</td>\n      <td>36.000000</td>\n    </tr>\n    <tr>\n      <th>3619</th>\n      <td>2015-12-17</td>\n      <td>39.250000</td>\n    </tr>\n    <tr>\n      <th>3620</th>\n      <td>2015-12-18</td>\n      <td>45.000000</td>\n    </tr>\n    <tr>\n      <th>3621</th>\n      <td>2015-12-19</td>\n      <td>37.727273</td>\n    </tr>\n    <tr>\n      <th>3622</th>\n      <td>2015-12-20</td>\n      <td>40.666667</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1680785918580
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Training and Testing set\n",
        "\n",
        "Since we plan on predicting whether patients would be readmitted in October, November or December, we split the training and testing data based on the date"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Split data based on time"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "date_cutoff = pd.to_datetime('2020-10-01')\n",
        "\n",
        "all_train_dfs = {}\n",
        "for city, df in city_wise_dfs.items():\n",
        "    train_df = df[df['date'] < date_cutoff]\n",
        "    all_train_dfs[city] = train_df\n",
        "\n",
        "all_train_dfs[city].head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "           date  wait_time\n7238 2015-12-16  43.000000\n7239 2015-12-17  42.111111\n7240 2015-12-18  40.444444\n7241 2015-12-19  41.052632\n7242 2015-12-20  40.500000",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>wait_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7238</th>\n      <td>2015-12-16</td>\n      <td>43.000000</td>\n    </tr>\n    <tr>\n      <th>7239</th>\n      <td>2015-12-17</td>\n      <td>42.111111</td>\n    </tr>\n    <tr>\n      <th>7240</th>\n      <td>2015-12-18</td>\n      <td>40.444444</td>\n    </tr>\n    <tr>\n      <th>7241</th>\n      <td>2015-12-19</td>\n      <td>41.052632</td>\n    </tr>\n    <tr>\n      <th>7242</th>\n      <td>2015-12-20</td>\n      <td>40.500000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1680785919217
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_test_dfs = {}\n",
        "for city, df in city_wise_dfs.items():\n",
        "    test_df = df[df['date'] >= date_cutoff]\n",
        "    all_test_dfs[city] = test_df\n",
        "    \n",
        "all_test_dfs['Honolulu'].head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "           date  wait_time\n5369 2020-10-01  42.799257\n5370 2020-10-02  41.120000\n5371 2020-10-03  41.098425\n5372 2020-10-04  42.310484\n5373 2020-10-05  42.034483",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>wait_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5369</th>\n      <td>2020-10-01</td>\n      <td>42.799257</td>\n    </tr>\n    <tr>\n      <th>5370</th>\n      <td>2020-10-02</td>\n      <td>41.120000</td>\n    </tr>\n    <tr>\n      <th>5371</th>\n      <td>2020-10-03</td>\n      <td>41.098425</td>\n    </tr>\n    <tr>\n      <th>5372</th>\n      <td>2020-10-04</td>\n      <td>42.310484</td>\n    </tr>\n    <tr>\n      <th>5373</th>\n      <td>2020-10-05</td>\n      <td>42.034483</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1680785919559
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Upload training and testing set to the Storage Account"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "local_data_folder = 'wait_time_data/'\n",
        "if not os.path.exists(local_data_folder):\n",
        "    os.mkdir(local_data_folder)\n",
        "\n",
        "base_train_file = 'wait_time_data_train_'\n",
        "base_test_file = 'wait_time_data_test_'\n",
        "\n",
        "local_files = []\n",
        "for city, train_df in all_train_dfs.items():\n",
        "    city_without_spaces = '-'.join(city.split(' '))\n",
        "  \n",
        "    # Save train file\n",
        "    train_file = base_train_file + city_without_spaces + '.csv'\n",
        "    train_df.to_csv(local_data_folder + train_file, index=False)\n",
        "    local_files.append(local_data_folder + train_file)\n",
        "    \n",
        "    # Save test file\n",
        "    test_file = base_test_file + city_without_spaces + '.csv'\n",
        "    test_df = all_test_dfs[city]\n",
        "    test_df.to_csv(local_data_folder + test_file, index=False)\n",
        "    local_files.append(local_data_folder + test_file)\n"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1680785919890
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the data\n",
        "print(local_files)\n",
        "\n",
        "dstore.upload_files(\n",
        "    files = local_files,\n",
        "    relative_root = local_data_folder,\n",
        "    target_path = '/',\n",
        "    overwrite=True,\n",
        "    show_progress=True\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['wait_time_data/wait_time_data_train_Anchorage.csv', 'wait_time_data/wait_time_data_test_Anchorage.csv', 'wait_time_data/wait_time_data_train_Chicago.csv', 'wait_time_data/wait_time_data_test_Chicago.csv', 'wait_time_data/wait_time_data_train_Honolulu.csv', 'wait_time_data/wait_time_data_test_Honolulu.csv', 'wait_time_data/wait_time_data_train_Los-Angeles.csv', 'wait_time_data/wait_time_data_test_Los-Angeles.csv', 'wait_time_data/wait_time_data_train_Miami.csv', 'wait_time_data/wait_time_data_test_Miami.csv']\nUploading an estimated of 10 files\nUploading wait_time_data/wait_time_data_train_Anchorage.csv\nUploaded wait_time_data/wait_time_data_train_Anchorage.csv, 1 files out of an estimated total of 10\nUploading wait_time_data/wait_time_data_test_Anchorage.csv\nUploaded wait_time_data/wait_time_data_test_Anchorage.csv, 2 files out of an estimated total of 10\nUploading wait_time_data/wait_time_data_train_Chicago.csv\nUploaded wait_time_data/wait_time_data_train_Chicago.csv, 3 files out of an estimated total of 10\nUploading wait_time_data/wait_time_data_test_Chicago.csv\nUploaded wait_time_data/wait_time_data_test_Chicago.csv, 4 files out of an estimated total of 10\nUploading wait_time_data/wait_time_data_train_Honolulu.csv\nUploaded wait_time_data/wait_time_data_train_Honolulu.csv, 5 files out of an estimated total of 10\nUploading wait_time_data/wait_time_data_test_Honolulu.csv\nUploaded wait_time_data/wait_time_data_test_Honolulu.csv, 6 files out of an estimated total of 10\nUploading wait_time_data/wait_time_data_train_Los-Angeles.csv\nUploaded wait_time_data/wait_time_data_train_Los-Angeles.csv, 7 files out of an estimated total of 10\nUploading wait_time_data/wait_time_data_test_Los-Angeles.csv\nUploaded wait_time_data/wait_time_data_test_Los-Angeles.csv, 8 files out of an estimated total of 10\nUploading wait_time_data/wait_time_data_train_Miami.csv\nUploaded wait_time_data/wait_time_data_train_Miami.csv, 9 files out of an estimated total of 10\nUploading wait_time_data/wait_time_data_test_Miami.csv\nUploaded wait_time_data/wait_time_data_test_Miami.csv, 10 files out of an estimated total of 10\nUploaded 10 files\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "$AZUREML_DATAREFERENCE_wait_time_prediction_store"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\"datastore.upload_files\" is deprecated after version 1.0.69. Please use \"FileDatasetFactory.upload_directory\" instead. See Dataset API change notice at https://aka.ms/dataset-deprecation.\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1680785920353
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up AutoML Experiment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set the Data Types for each column. \n",
        "This needs to be done explicitly since some ID columns are automatically inferred as integers, when they should be treated as strings"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data import DataType\n",
        "\n",
        "data_types = {\n",
        "    'wait_time': DataType.to_long(),\n",
        "    'date': DataType.to_datetime(\"%Y-%m-%d\"),\n",
        "}\n",
        "\n",
        "print(len(data_types))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1680785920617
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_train_dfs.keys()\r\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "dict_keys(['Anchorage', 'Chicago', 'Honolulu', 'Los Angeles', 'Miami'])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1680785920930
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load Training data from Storage Blob as a TabularDataSet"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "all_train_datasets = {}\n",
        "for city in all_train_dfs.keys():\n",
        "    filepath = base_train_file + city_without_spaces + '.csv'\n",
        "\n",
        "    datastore_path = [DataPath(dstore, filepath)]\n",
        "    traindataset = Dataset.Tabular.from_delimited_files(path=datastore_path)\n",
        "    traindataset.to_pandas_dataframe().info()\n",
        "    all_train_datasets[city] = traindataset\n",
        "    \n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1751 entries, 0 to 1750\nData columns (total 2 columns):\n #   Column     Non-Null Count  Dtype         \n---  ------     --------------  -----         \n 0   date       1751 non-null   datetime64[ns]\n 1   wait_time  1751 non-null   float64       \ndtypes: datetime64[ns](1), float64(1)\nmemory usage: 27.5 KB\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1751 entries, 0 to 1750\nData columns (total 2 columns):\n #   Column     Non-Null Count  Dtype         \n---  ------     --------------  -----         \n 0   date       1751 non-null   datetime64[ns]\n 1   wait_time  1751 non-null   float64       \ndtypes: datetime64[ns](1), float64(1)\nmemory usage: 27.5 KB\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1751 entries, 0 to 1750\nData columns (total 2 columns):\n #   Column     Non-Null Count  Dtype         \n---  ------     --------------  -----         \n 0   date       1751 non-null   datetime64[ns]\n 1   wait_time  1751 non-null   float64       \ndtypes: datetime64[ns](1), float64(1)\nmemory usage: 27.5 KB\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1751 entries, 0 to 1750\nData columns (total 2 columns):\n #   Column     Non-Null Count  Dtype         \n---  ------     --------------  -----         \n 0   date       1751 non-null   datetime64[ns]\n 1   wait_time  1751 non-null   float64       \ndtypes: datetime64[ns](1), float64(1)\nmemory usage: 27.5 KB\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1751 entries, 0 to 1750\nData columns (total 2 columns):\n #   Column     Non-Null Count  Dtype         \n---  ------     --------------  -----         \n 0   date       1751 non-null   datetime64[ns]\n 1   wait_time  1751 non-null   float64       \ndtypes: datetime64[ns](1), float64(1)\nmemory usage: 27.5 KB\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1680785921365
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_variable = \"wait_time\""
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1680785921693
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setup Computer Instances"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import AmlCompute\n",
        "\n",
        "compute = AmlCompute(ws, \"health-cluster\")"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1680785921953
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Configure the AutoML model and run it"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.experiment import Experiment\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "for city, traindataset in all_train_datasets.items():\n",
        "    city_without_spaces = '-'.join(city.split(' '))\n",
        "    experiment_name = 'Waittime-Forecasting-Experiment_' + city_without_spaces\n",
        "    experiment = Experiment(ws, experiment_name)\n",
        "\n",
        "    automl_config = AutoMLConfig(task = 'forecasting',\n",
        "                         debug_log = 'automl_errors.log',\n",
        "                         iteration_timeout_minutes = 15,\n",
        "                         n_cross_validations=3,\n",
        "                         experiment_timeout_minutes = 15,\n",
        "                         label_column_name=y_variable,\n",
        "                         time_column_name='date',\n",
        "                         enable_early_stopping=True,\n",
        "                         compute_target = compute,\n",
        "                         training_data = traindataset,\n",
        "                         model_explainability=True)\n",
        "\n",
        "    training_run = experiment.submit(automl_config, show_output = True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Submitting remote run.\nNo run_configuration provided, running on health-cluster with default configuration\nRunning on remote compute: health-cluster\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>Waittime-Forecasting-Experiment_Anchorage</td><td>AutoML_77a6e913-2dd7-4256-9a91-2a55e6e74220</td><td>automl</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/AutoML_77a6e913-2dd7-4256-9a91-2a55e6e74220?wsid=/subscriptions/506e86fc-853c-4557-a6e5-ad72114efd2b/resourcegroups/rg-healthcare2-prod/workspaces/mlw-healthcare2-prod&amp;tid=f94768c8-8714-4abe-8e2d-37a64b18216a\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nCurrent status: ModelSelection. Beginning model selection.\n\n********************************************************************************************\nDATA GUARDRAILS: \n\nTYPE:         Time Series ID detection\nSTATUS:       PASSED\nDESCRIPTION:  The data set was analyzed, and no duplicate time index were detected.\n              Learn more about time-series forecasting configurations: https://aka.ms/AutomatedMLForecastingConfiguration\n\n********************************************************************************************\n\nTYPE:         Short series handling\nSTATUS:       PASSED\nDESCRIPTION:  Automated ML detected enough data points for each series in the input data to continue with training.\n              Learn more about short series handling: https://aka.ms/AutomatedMLShortSeriesHandling\n\n********************************************************************************************\n\nTYPE:         Frequency detection\nSTATUS:       PASSED\nDESCRIPTION:  The time series was analyzed, all data points are aligned with detected frequency.\n              Learn more about data preparation for time-series forecasting: https://aka.ms/AutomatedMLDataPreparation\n\n********************************************************************************************\n\nTYPE:         Missing feature values imputation\nSTATUS:       PASSED\nDESCRIPTION:  No feature missing values were detected in the training data.\n              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n\n********************************************************************************************\n\nTYPE:         Automatic cross validation\nSTATUS:       DONE\nDESCRIPTION:  Cross validation parameter(s) were automatically set for your dataset.\n              Learn more about time-series forecasting configurations: https://aka.ms/AutomatedMLForecastingConfiguration\nDETAILS:      If n_cross_validations and/or cv_step_size is not specified, Automated ML will determine those cross validation parameters automatically for you.\n+----------------------------------------------------------------+\n|Number of periods between two consecutive cross validation folds|\n+================================================================+\n|1                                                               |\n+----------------------------------------------------------------+\n\n********************************************************************************************\n\n********************************************************************************************\nITER: The iteration being evaluated.\nPIPELINE: A summary description of the pipeline being evaluated.\nDURATION: Time taken for the current iteration.\nMETRIC: The result of computing score on the fitted pipeline.\nBEST: The best observed score thus far.\n********************************************************************************************\n\n ITER   PIPELINE                                       DURATION            METRIC      BEST\n    0    Naive                                         0:00:29             0.2660    0.2660\n    1    SeasonalNaive                                 0:00:27             0.1350    0.1350\n    2    Average                                       0:00:28             0.1958    0.1350\n    3    SeasonalAverage                               0:00:28             0.1544    0.1350\n    4    ExponentialSmoothing                          0:00:49             0.1810    0.1350\n    5    AutoArima                                     0:02:03             0.1878    0.1350\n    6    ProphetModel                                  0:00:42             0.1912    0.1350\n    7   StandardScalerWrapper LightGBM                 0:00:30             0.1689    0.1350\n    8   StandardScalerWrapper XGBoostRegressor         0:00:29             0.2072    0.1350\n    9   MaxAbsScaler ElasticNet                        0:00:29             0.1945    0.1350\n   10   RobustScaler ElasticNet                        0:00:29             0.1852    0.1350\n   11   MinMaxScaler ElasticNet                        0:00:28             0.1851    0.1350\n   12   StandardScalerWrapper ElasticNet               0:00:28             0.1854    0.1350\n   13   MinMaxScaler RandomForest                      0:00:27             0.1379    0.1350\n   14   MaxAbsScaler ElasticNet                        0:00:28             0.1945    0.1350\n   15   StandardScalerWrapper ElasticNet               0:00:28             0.1853    0.1350\n   16   MaxAbsScaler ElasticNet                        0:00:28             0.1944    0.1350\n   17   StandardScalerWrapper ElasticNet               0:00:28             0.1853    0.1350\n   18   MinMaxScaler ExtremeRandomTrees                0:00:28             0.1509    0.1350\n   19   MinMaxScaler RandomForest                      0:00:28             0.1433    0.1350\n   20   MinMaxScaler ExtremeRandomTrees                0:00:54             0.1723    0.1350\n   21    VotingEnsemble                                0:01:05             0.1352    0.1350\nSubmitting remote run.\nNo run_configuration provided, running on health-cluster with default configuration\nRunning on remote compute: health-cluster\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>Waittime-Forecasting-Experiment_Chicago</td><td>AutoML_0e222fce-c9d3-4d6e-95c4-0c3c1b70f621</td><td>automl</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/AutoML_0e222fce-c9d3-4d6e-95c4-0c3c1b70f621?wsid=/subscriptions/506e86fc-853c-4557-a6e5-ad72114efd2b/resourcegroups/rg-healthcare2-prod/workspaces/mlw-healthcare2-prod&amp;tid=f94768c8-8714-4abe-8e2d-37a64b18216a\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nCurrent status: ModelSelection. Beginning model selection.\n\n********************************************************************************************\nDATA GUARDRAILS: \n\nTYPE:         Time Series ID detection\nSTATUS:       PASSED\nDESCRIPTION:  The data set was analyzed, and no duplicate time index were detected.\n              Learn more about time-series forecasting configurations: https://aka.ms/AutomatedMLForecastingConfiguration\n\n********************************************************************************************\n\nTYPE:         Short series handling\nSTATUS:       PASSED\nDESCRIPTION:  Automated ML detected enough data points for each series in the input data to continue with training.\n              Learn more about short series handling: https://aka.ms/AutomatedMLShortSeriesHandling\n\n********************************************************************************************\n\nTYPE:         Frequency detection\nSTATUS:       PASSED\nDESCRIPTION:  The time series was analyzed, all data points are aligned with detected frequency.\n              Learn more about data preparation for time-series forecasting: https://aka.ms/AutomatedMLDataPreparation\n\n********************************************************************************************\n\nTYPE:         Missing feature values imputation\nSTATUS:       PASSED\nDESCRIPTION:  No feature missing values were detected in the training data.\n              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n\n********************************************************************************************\n\nTYPE:         Automatic cross validation\nSTATUS:       DONE\nDESCRIPTION:  Cross validation parameter(s) were automatically set for your dataset.\n              Learn more about time-series forecasting configurations: https://aka.ms/AutomatedMLForecastingConfiguration\nDETAILS:      If n_cross_validations and/or cv_step_size is not specified, Automated ML will determine those cross validation parameters automatically for you.\n+----------------------------------------------------------------+\n|Number of periods between two consecutive cross validation folds|\n+================================================================+\n|1                                                               |\n+----------------------------------------------------------------+\n\n********************************************************************************************\n\n********************************************************************************************\nITER: The iteration being evaluated.\nPIPELINE: A summary description of the pipeline being evaluated.\nDURATION: Time taken for the current iteration.\nMETRIC: The result of computing score on the fitted pipeline.\nBEST: The best observed score thus far.\n********************************************************************************************\n\n ITER   PIPELINE                                       DURATION            METRIC      BEST\n    0    Naive                                         0:00:28             0.2660    0.2660\n    1    SeasonalNaive                                 0:00:30             0.1350    0.1350\n    2    Average                                       0:01:06             0.1958    0.1350\n    3    SeasonalAverage                               0:00:28             0.1544    0.1350\n    4    ExponentialSmoothing                          0:00:48             0.1810    0.1350\n    5    AutoArima                                     0:02:03             0.1878    0.1350\n    6    ProphetModel                                  0:00:41             0.1912    0.1350\n    7   StandardScalerWrapper LightGBM                 0:00:30             0.1689    0.1350\n    8   StandardScalerWrapper XGBoostRegressor         0:00:31             0.2072    0.1350\n    9   MaxAbsScaler ElasticNet                        0:00:28             0.1945    0.1350\n   10   RobustScaler ElasticNet                        0:00:28             0.1852    0.1350\n   11   MinMaxScaler ElasticNet                        0:00:28             0.1851    0.1350\n   12   StandardScalerWrapper ElasticNet               0:00:28             0.1854    0.1350\n   13   MinMaxScaler RandomForest                      0:00:29             0.1329    0.1329\n   14   MaxAbsScaler ElasticNet                        0:00:28             0.1945    0.1329\n   15   StandardScalerWrapper ElasticNet               0:00:29             0.1853    0.1329\n   16   MaxAbsScaler ElasticNet                        0:00:28             0.1944    0.1329\n   17   StandardScalerWrapper ElasticNet               0:00:28             0.1853    0.1329\n   18   MinMaxScaler ExtremeRandomTrees                0:00:28             0.1523    0.1329\n   19   MinMaxScaler RandomForest                      0:00:29             0.1543    0.1329\n   20    VotingEnsemble                                0:09:12             0.1330    0.1329\nSubmitting remote run.\nNo run_configuration provided, running on health-cluster with default configuration\nRunning on remote compute: health-cluster\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>Waittime-Forecasting-Experiment_Honolulu</td><td>AutoML_9974eb2c-a84d-40b9-8919-733cab3ec8c5</td><td>automl</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/AutoML_9974eb2c-a84d-40b9-8919-733cab3ec8c5?wsid=/subscriptions/506e86fc-853c-4557-a6e5-ad72114efd2b/resourcegroups/rg-healthcare2-prod/workspaces/mlw-healthcare2-prod&amp;tid=f94768c8-8714-4abe-8e2d-37a64b18216a\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nCurrent status: ModelSelection. Beginning model selection.\n\n********************************************************************************************\nDATA GUARDRAILS: \n\nTYPE:         Time Series ID detection\nSTATUS:       PASSED\nDESCRIPTION:  The data set was analyzed, and no duplicate time index were detected.\n              Learn more about time-series forecasting configurations: https://aka.ms/AutomatedMLForecastingConfiguration\n\n********************************************************************************************\n\nTYPE:         Short series handling\nSTATUS:       PASSED\nDESCRIPTION:  Automated ML detected enough data points for each series in the input data to continue with training.\n              Learn more about short series handling: https://aka.ms/AutomatedMLShortSeriesHandling\n\n********************************************************************************************\n\nTYPE:         Frequency detection\nSTATUS:       PASSED\nDESCRIPTION:  The time series was analyzed, all data points are aligned with detected frequency.\n              Learn more about data preparation for time-series forecasting: https://aka.ms/AutomatedMLDataPreparation\n\n********************************************************************************************\n\nTYPE:         Missing feature values imputation\nSTATUS:       PASSED\nDESCRIPTION:  No feature missing values were detected in the training data.\n              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n\n********************************************************************************************\n\nTYPE:         Automatic cross validation\nSTATUS:       DONE\nDESCRIPTION:  Cross validation parameter(s) were automatically set for your dataset.\n              Learn more about time-series forecasting configurations: https://aka.ms/AutomatedMLForecastingConfiguration\nDETAILS:      If n_cross_validations and/or cv_step_size is not specified, Automated ML will determine those cross validation parameters automatically for you.\n+----------------------------------------------------------------+\n|Number of periods between two consecutive cross validation folds|\n+================================================================+\n|1                                                               |\n+----------------------------------------------------------------+\n\n********************************************************************************************\n\n********************************************************************************************\nITER: The iteration being evaluated.\nPIPELINE: A summary description of the pipeline being evaluated.\nDURATION: Time taken for the current iteration.\nMETRIC: The result of computing score on the fitted pipeline.\nBEST: The best observed score thus far.\n********************************************************************************************\n\n ITER   PIPELINE                                       DURATION            METRIC      BEST\n    0    Naive                                         0:00:27             0.2660    0.2660\n    1    SeasonalNaive                                 0:00:26             0.1350    0.1350\n    2    Average                                       0:00:27             0.1958    0.1350\n    3    SeasonalAverage                               0:00:26             0.1544    0.1350\n    4    ExponentialSmoothing                          0:00:45             0.1810    0.1350\n    5    AutoArima                                     0:01:58             0.1878    0.1350\n    6    ProphetModel                                  0:00:37             0.1912    0.1350\n    7   StandardScalerWrapper LightGBM                 0:00:26             0.1689    0.1350\n    8   StandardScalerWrapper XGBoostRegressor         0:00:28             0.2072    0.1350\n    9   MaxAbsScaler ElasticNet                        0:00:29             0.1945    0.1350\n   10   RobustScaler ElasticNet                        0:00:27             0.1852    0.1350\n   11   MinMaxScaler ElasticNet                        0:00:27             0.1851    0.1350\n   12   StandardScalerWrapper ElasticNet               0:00:27             0.1854    0.1350\n   13   MinMaxScaler RandomForest                      0:00:27             0.1418    0.1350\n   14   MaxAbsScaler ElasticNet                        0:00:27             0.1945    0.1350\n   15   StandardScalerWrapper ElasticNet               0:00:28             0.1853    0.1350\n   16   MaxAbsScaler ElasticNet                        0:00:27             0.1944    0.1350\n   17   StandardScalerWrapper ElasticNet               0:00:28             0.1853    0.1350\n   18   MinMaxScaler ExtremeRandomTrees                0:00:27             0.1606    0.1350\n   19   MinMaxScaler RandomForest                      0:00:27             0.1458    0.1350\n   20    VotingEnsemble                                0:02:30             0.1350    0.1350\nSubmitting remote run.\nNo run_configuration provided, running on health-cluster with default configuration\nRunning on remote compute: health-cluster\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>Waittime-Forecasting-Experiment_Los-Angeles</td><td>AutoML_c9d3dc5f-65ce-4259-8795-24cd413833dd</td><td>automl</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/AutoML_c9d3dc5f-65ce-4259-8795-24cd413833dd?wsid=/subscriptions/506e86fc-853c-4557-a6e5-ad72114efd2b/resourcegroups/rg-healthcare2-prod/workspaces/mlw-healthcare2-prod&amp;tid=f94768c8-8714-4abe-8e2d-37a64b18216a\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nCurrent status: ModelSelection. Beginning model selection.\n\n********************************************************************************************\nDATA GUARDRAILS: \n\nTYPE:         Time Series ID detection\nSTATUS:       PASSED\nDESCRIPTION:  The data set was analyzed, and no duplicate time index were detected.\n              Learn more about time-series forecasting configurations: https://aka.ms/AutomatedMLForecastingConfiguration\n\n********************************************************************************************\n\nTYPE:         Short series handling\nSTATUS:       PASSED\nDESCRIPTION:  Automated ML detected enough data points for each series in the input data to continue with training.\n              Learn more about short series handling: https://aka.ms/AutomatedMLShortSeriesHandling\n\n********************************************************************************************\n\nTYPE:         Frequency detection\nSTATUS:       PASSED\nDESCRIPTION:  The time series was analyzed, all data points are aligned with detected frequency.\n              Learn more about data preparation for time-series forecasting: https://aka.ms/AutomatedMLDataPreparation\n\n********************************************************************************************\n\nTYPE:         Missing feature values imputation\nSTATUS:       PASSED\nDESCRIPTION:  No feature missing values were detected in the training data.\n              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n\n********************************************************************************************\n\nTYPE:         Automatic cross validation\nSTATUS:       DONE\nDESCRIPTION:  Cross validation parameter(s) were automatically set for your dataset.\n              Learn more about time-series forecasting configurations: https://aka.ms/AutomatedMLForecastingConfiguration\nDETAILS:      If n_cross_validations and/or cv_step_size is not specified, Automated ML will determine those cross validation parameters automatically for you.\n+----------------------------------------------------------------+\n|Number of periods between two consecutive cross validation folds|\n+================================================================+\n|1                                                               |\n+----------------------------------------------------------------+\n\n********************************************************************************************\n\n********************************************************************************************\nITER: The iteration being evaluated.\nPIPELINE: A summary description of the pipeline being evaluated.\nDURATION: Time taken for the current iteration.\nMETRIC: The result of computing score on the fitted pipeline.\nBEST: The best observed score thus far.\n********************************************************************************************\n\n ITER   PIPELINE                                       DURATION            METRIC      BEST\n    0    Naive                                         0:00:28             0.2660    0.2660\n    1    SeasonalNaive                                 0:00:28             0.1350    0.1350\n    2    Average                                       0:00:25             0.1958    0.1350\n    3    SeasonalAverage                               0:00:25             0.1544    0.1350\n    4    ExponentialSmoothing                          0:00:42             0.1810    0.1350\n    5    AutoArima                                     0:01:45             0.1878    0.1350\n    6    ProphetModel                                  0:00:35             0.1912    0.1350\n    7   StandardScalerWrapper LightGBM                 0:00:25             0.1689    0.1350\n    8   StandardScalerWrapper XGBoostRegressor         0:00:26             0.2072    0.1350\n    9   MaxAbsScaler ElasticNet                        0:00:26             0.1945    0.1350\n   10   RobustScaler ElasticNet                        0:00:26             0.1852    0.1350\n   11   MinMaxScaler ElasticNet                        0:00:25             0.1851    0.1350\n   12   StandardScalerWrapper ElasticNet               0:00:25             0.1854    0.1350\n   13   MinMaxScaler RandomForest                      0:00:26             0.1666    0.1350\n   14   MaxAbsScaler ElasticNet                        0:00:25             0.1945    0.1350\n   15   StandardScalerWrapper ElasticNet               0:00:24             0.1853    0.1350\n   16   MaxAbsScaler ElasticNet                        0:00:25             0.1944    0.1350\n   17   StandardScalerWrapper ElasticNet               0:00:25             0.1853    0.1350\n   18   MinMaxScaler ExtremeRandomTrees                0:00:24             0.1570    0.1350\n   19   MinMaxScaler RandomForest                      0:00:25             0.1463    0.1350\n   20   MinMaxScaler ExtremeRandomTrees                0:00:46             0.1703    0.1350\n   21   MinMaxScaler ExtremeRandomTrees                0:00:45             0.1674    0.1350\n   22   MaxAbsScaler ExtremeRandomTrees                0:00:45             0.1898    0.1350\n   23    VotingEnsemble                                0:00:53             0.1350    0.1350\nSubmitting remote run.\nNo run_configuration provided, running on health-cluster with default configuration\nRunning on remote compute: health-cluster\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>Waittime-Forecasting-Experiment_Miami</td><td>AutoML_5116e1a1-1d01-4446-8cad-57f985c7e117</td><td>automl</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/AutoML_5116e1a1-1d01-4446-8cad-57f985c7e117?wsid=/subscriptions/506e86fc-853c-4557-a6e5-ad72114efd2b/resourcegroups/rg-healthcare2-prod/workspaces/mlw-healthcare2-prod&amp;tid=f94768c8-8714-4abe-8e2d-37a64b18216a\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nCurrent status: ModelSelection. Beginning model selection.\n\n********************************************************************************************\nDATA GUARDRAILS: \n\nTYPE:         Time Series ID detection\nSTATUS:       PASSED\nDESCRIPTION:  The data set was analyzed, and no duplicate time index were detected.\n              Learn more about time-series forecasting configurations: https://aka.ms/AutomatedMLForecastingConfiguration\n\n********************************************************************************************\n\nTYPE:         Short series handling\nSTATUS:       PASSED\nDESCRIPTION:  Automated ML detected enough data points for each series in the input data to continue with training.\n              Learn more about short series handling: https://aka.ms/AutomatedMLShortSeriesHandling\n\n********************************************************************************************\n\nTYPE:         Frequency detection\nSTATUS:       PASSED\nDESCRIPTION:  The time series was analyzed, all data points are aligned with detected frequency.\n              Learn more about data preparation for time-series forecasting: https://aka.ms/AutomatedMLDataPreparation\n\n********************************************************************************************\n\nTYPE:         Missing feature values imputation\nSTATUS:       PASSED\nDESCRIPTION:  No feature missing values were detected in the training data.\n              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n\n********************************************************************************************\n\nTYPE:         Automatic cross validation\nSTATUS:       DONE\nDESCRIPTION:  Cross validation parameter(s) were automatically set for your dataset.\n              Learn more about time-series forecasting configurations: https://aka.ms/AutomatedMLForecastingConfiguration\nDETAILS:      If n_cross_validations and/or cv_step_size is not specified, Automated ML will determine those cross validation parameters automatically for you.\n+----------------------------------------------------------------+\n|Number of periods between two consecutive cross validation folds|\n+================================================================+\n|1                                                               |\n+----------------------------------------------------------------+\n\n********************************************************************************************\n\n********************************************************************************************\nITER: The iteration being evaluated.\nPIPELINE: A summary description of the pipeline being evaluated.\nDURATION: Time taken for the current iteration.\nMETRIC: The result of computing score on the fitted pipeline.\nBEST: The best observed score thus far.\n********************************************************************************************\n\n ITER   PIPELINE                                       DURATION            METRIC      BEST\n    0    Naive                                         0:00:24             0.2660    0.2660\n    1    SeasonalNaive                                 0:00:25             0.1350    0.1350\n    2    Average                                       0:00:24             0.1958    0.1350\n    3    SeasonalAverage                               0:00:25             0.1544    0.1350\n    4    ExponentialSmoothing                          0:00:41             0.1810    0.1350\n    5    AutoArima                                     0:01:46             0.1878    0.1350\n    6    ProphetModel                                  0:00:36             0.1912    0.1350\n    7   StandardScalerWrapper LightGBM                 0:00:25             0.1689    0.1350\n    8   StandardScalerWrapper XGBoostRegressor         0:00:27             0.2072    0.1350\n    9   MaxAbsScaler ElasticNet                        0:00:25             0.1945    0.1350\n   10   RobustScaler ElasticNet                        0:00:25             0.1852    0.1350\n   11   MinMaxScaler ElasticNet                        0:00:25             0.1851    0.1350\n   12   StandardScalerWrapper ElasticNet               0:00:25             0.1854    0.1350\n   13   MinMaxScaler RandomForest                      0:00:25             0.1544    0.1350\n   14   MaxAbsScaler ElasticNet                        0:00:25             0.1945    0.1350\n   15   StandardScalerWrapper ElasticNet               0:00:25             0.1853    0.1350\n   16   MaxAbsScaler ElasticNet                        0:00:24             0.1944    0.1350\n   17   StandardScalerWrapper ElasticNet               0:00:25             0.1853    0.1350\n   18   MinMaxScaler ExtremeRandomTrees                0:00:25             0.1607    0.1350\n   19   MinMaxScaler RandomForest                      0:00:25             0.1420    0.1350\n   20   MinMaxScaler ExtremeRandomTrees                0:00:45             0.1603    0.1350\n   21   MinMaxScaler ExtremeRandomTrees                0:00:46             0.1720    0.1350\n   22   MaxAbsScaler ExtremeRandomTrees                0:00:45             0.1556    0.1350\n   23    VotingEnsemble                                0:00:55             0.1350    0.1350\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1680794268493
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Retrieve model to predict the test set"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "autoMLRunIds = {\n",
        "    'Miami': 'AutoML_5116e1a1-1d01-4446-8cad-57f985c7e117',\n",
        "    'Los Angeles': 'AutoML_c9d3dc5f-65ce-4259-8795-24cd413833dd',\n",
        "    'Honolulu': 'AutoML_9974eb2c-a84d-40b9-8919-733cab3ec8c5',\n",
        "    'Chicago': 'AutoML_0e222fce-c9d3-4d6e-95c4-0c3c1b70f621',\n",
        "    'Anchorage': 'AutoML_77a6e913-2dd7-4256-9a91-2a55e6e74220',    \n",
        "}"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1680795877768
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl.run import AutoMLRun\n",
        "\n",
        "all_automl_runs = {}\n",
        "for city, autoMLRunId in autoMLRunIds.items():\n",
        "    city_without_spaces = '-'.join(city.split(' '))\n",
        "    experiment_name = 'Waittime-Forecasting-Experiment_' + city_without_spaces\n",
        "\n",
        "    experiment = Experiment(workspace = ws, name = experiment_name)\n",
        "    automl_run = AutoMLRun(experiment, autoMLRunId, outputs = None)\n",
        "    display(automl_run)\n",
        "    all_automl_runs[city] = automl_run"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Run(Experiment: Waittime-Forecasting-Experiment_Miami,\nId: AutoML_5116e1a1-1d01-4446-8cad-57f985c7e117,\nType: automl,\nStatus: Completed)",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>Waittime-Forecasting-Experiment_Miami</td><td>AutoML_5116e1a1-1d01-4446-8cad-57f985c7e117</td><td>automl</td><td>Completed</td><td><a href=\"https://ml.azure.com/runs/AutoML_5116e1a1-1d01-4446-8cad-57f985c7e117?wsid=/subscriptions/506e86fc-853c-4557-a6e5-ad72114efd2b/resourcegroups/rg-healthcare2-prod/workspaces/mlw-healthcare2-prod&amp;tid=f94768c8-8714-4abe-8e2d-37a64b18216a\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Run(Experiment: Waittime-Forecasting-Experiment_Los-Angeles,\nId: AutoML_c9d3dc5f-65ce-4259-8795-24cd413833dd,\nType: automl,\nStatus: Completed)",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>Waittime-Forecasting-Experiment_Los-Angeles</td><td>AutoML_c9d3dc5f-65ce-4259-8795-24cd413833dd</td><td>automl</td><td>Completed</td><td><a href=\"https://ml.azure.com/runs/AutoML_c9d3dc5f-65ce-4259-8795-24cd413833dd?wsid=/subscriptions/506e86fc-853c-4557-a6e5-ad72114efd2b/resourcegroups/rg-healthcare2-prod/workspaces/mlw-healthcare2-prod&amp;tid=f94768c8-8714-4abe-8e2d-37a64b18216a\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Run(Experiment: Waittime-Forecasting-Experiment_Honolulu,\nId: AutoML_9974eb2c-a84d-40b9-8919-733cab3ec8c5,\nType: automl,\nStatus: Completed)",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>Waittime-Forecasting-Experiment_Honolulu</td><td>AutoML_9974eb2c-a84d-40b9-8919-733cab3ec8c5</td><td>automl</td><td>Completed</td><td><a href=\"https://ml.azure.com/runs/AutoML_9974eb2c-a84d-40b9-8919-733cab3ec8c5?wsid=/subscriptions/506e86fc-853c-4557-a6e5-ad72114efd2b/resourcegroups/rg-healthcare2-prod/workspaces/mlw-healthcare2-prod&amp;tid=f94768c8-8714-4abe-8e2d-37a64b18216a\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Run(Experiment: Waittime-Forecasting-Experiment_Chicago,\nId: AutoML_0e222fce-c9d3-4d6e-95c4-0c3c1b70f621,\nType: automl,\nStatus: Completed)",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>Waittime-Forecasting-Experiment_Chicago</td><td>AutoML_0e222fce-c9d3-4d6e-95c4-0c3c1b70f621</td><td>automl</td><td>Completed</td><td><a href=\"https://ml.azure.com/runs/AutoML_0e222fce-c9d3-4d6e-95c4-0c3c1b70f621?wsid=/subscriptions/506e86fc-853c-4557-a6e5-ad72114efd2b/resourcegroups/rg-healthcare2-prod/workspaces/mlw-healthcare2-prod&amp;tid=f94768c8-8714-4abe-8e2d-37a64b18216a\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Run(Experiment: Waittime-Forecasting-Experiment_Anchorage,\nId: AutoML_77a6e913-2dd7-4256-9a91-2a55e6e74220,\nType: automl,\nStatus: Completed)",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>Waittime-Forecasting-Experiment_Anchorage</td><td>AutoML_77a6e913-2dd7-4256-9a91-2a55e6e74220</td><td>automl</td><td>Completed</td><td><a href=\"https://ml.azure.com/runs/AutoML_77a6e913-2dd7-4256-9a91-2a55e6e74220?wsid=/subscriptions/506e86fc-853c-4557-a6e5-ad72114efd2b/resourcegroups/rg-healthcare2-prod/workspaces/mlw-healthcare2-prod&amp;tid=f94768c8-8714-4abe-8e2d-37a64b18216a\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1680795886129
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_models = {}\n",
        "\n",
        "for city, automl_run in all_automl_runs.items():\n",
        "    best_run, fitted_model = automl_run.get_output()\n",
        "    # print(fitted_model.steps)\n",
        "    model_name = best_run.properties['model_name']\n",
        "    print(model_name)\n",
        "    all_models[city] = fitted_model"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "AutoML5116e1a111\nAutoMLc9d3dc5f61\nAutoML9974eb2ca1\nAutoML0e222fcec13\nAutoML77a6e91321\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1680795899409
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_models['Honolulu']"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": "ForecastingPipelineWrapper(pipeline=Pipeline(memory=None,\n                                             steps=[('timeseriestransformer',\n                                                     TimeSeriesTransformer(country_or_region=None, drop_column_names=[], featurization_config=FeaturizationConfig(blocked_transformers=None, column_purposes=None, dataset_language=None, prediction_transform_type=None, transformer_params=None), force_time_index_features=Non...\n                                                     SeasonalNaive(timeseries_param_dict={'time_column_name': 'date', 'grain_column_names': None, 'target_column_name': 'wait_time', 'drop_column_names': [], 'overwrite_columns': True, 'dropna': False, 'transform_dictionary': {'min': '_automl_target_col', 'max': '_automl_target_col', 'mean': '_automl_target_col'}, 'max_horizon': 1, 'origin_time_colname': 'origin', 'country_or_region': None, 'n_cross_validations': 3, 'short_series_handling': True, 'max_cores_per_iteration': 1, 'feature_lags': None, 'target_aggregation_function': None, 'cv_step_size': 1, 'iteration_timeout_minutes': 15, 'seasonality': 7, 'use_stl': None, 'freq': 'D', 'short_series_handling_configuration': 'auto', 'target_lags': [0], 'target_rolling_window_size': 0, 'arimax_raw_columns': ['date']}))],\n                                             verbose=False),\n                           stddev=[1.4141165747988025])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1680795904588
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Upload predictions to storage account\n",
        "\n",
        "The test_df also contains the y_variable which needs to be dropped"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_df = pd.DataFrame({'date': pd.date_range(start='2020-10-01', end='2020-12-31')})\n",
        "X_test_df"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": "         date\n0  2020-10-01\n1  2020-10-02\n2  2020-10-03\n3  2020-10-04\n4  2020-10-05\n..        ...\n87 2020-12-27\n88 2020-12-28\n89 2020-12-29\n90 2020-12-30\n91 2020-12-31\n\n[92 rows x 1 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-10-01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-10-02</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-10-03</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-10-04</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-10-05</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>2020-12-27</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>2020-12-28</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>2020-12-29</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>2020-12-30</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>2020-12-31</td>\n    </tr>\n  </tbody>\n</table>\n<p>92 rows × 1 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1680795909451
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_predictions = {}\n",
        "for city, fitted_model in all_models.items():\n",
        "    predictions = fitted_model.forecast(X_test_df)\n",
        "    display(predictions)\n",
        "    all_predictions[city] = predictions"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "(array([41.59753086, 40.74111675, 40.5495283 , 41.03846154, 41.84827586,\n        38.55882353, 41.41666667, 41.59753086, 40.74111675, 40.5495283 ,\n        41.03846154, 41.84827586, 38.55882353, 41.41666667, 41.59753086,\n        40.74111675, 40.5495283 , 41.03846154, 41.84827586, 38.55882353,\n        41.41666667, 41.59753086, 40.74111675, 40.5495283 , 41.03846154,\n        41.84827586, 38.55882353, 41.41666667, 41.59753086, 40.74111675,\n        40.5495283 , 41.03846154, 41.84827586, 38.55882353, 41.41666667,\n        41.59753086, 40.74111675, 40.5495283 , 41.03846154, 41.84827586,\n        38.55882353, 41.41666667, 41.59753086, 40.74111675, 40.5495283 ,\n        41.03846154, 41.84827586, 38.55882353, 41.41666667, 41.59753086,\n        40.74111675, 40.5495283 , 41.03846154, 41.84827586, 38.55882353,\n        41.41666667, 41.59753086, 40.74111675, 40.5495283 , 41.03846154,\n        41.84827586, 38.55882353, 41.41666667, 41.59753086, 40.74111675,\n        40.5495283 , 41.03846154, 41.84827586, 38.55882353, 41.41666667,\n        41.59753086, 40.74111675, 40.5495283 , 41.03846154, 41.84827586,\n        38.55882353, 41.41666667, 41.59753086, 40.74111675, 40.5495283 ,\n        41.03846154, 41.84827586, 38.55882353, 41.41666667, 41.59753086,\n        40.74111675, 40.5495283 , 41.03846154, 41.84827586, 38.55882353,\n        41.41666667, 41.59753086]),\n                                     _automl_target_col_WASNULL  _automl_year  \\\n date       _automl_dummy_grain_col                                             \n 2020-10-01 _automl_dummy_grain_col                           0          2020   \n 2020-10-02 _automl_dummy_grain_col                           0          2020   \n 2020-10-03 _automl_dummy_grain_col                           0          2020   \n 2020-10-04 _automl_dummy_grain_col                           0          2020   \n 2020-10-05 _automl_dummy_grain_col                           0          2020   \n ...                                                        ...           ...   \n 2020-12-27 _automl_dummy_grain_col                           0          2020   \n 2020-12-28 _automl_dummy_grain_col                           0          2020   \n 2020-12-29 _automl_dummy_grain_col                           0          2020   \n 2020-12-30 _automl_dummy_grain_col                           0          2020   \n 2020-12-31 _automl_dummy_grain_col                           0          2020   \n \n                                     _automl_half  _automl_quarter  \\\n date       _automl_dummy_grain_col                                  \n 2020-10-01 _automl_dummy_grain_col             2                4   \n 2020-10-02 _automl_dummy_grain_col             2                4   \n 2020-10-03 _automl_dummy_grain_col             2                4   \n 2020-10-04 _automl_dummy_grain_col             2                4   \n 2020-10-05 _automl_dummy_grain_col             2                4   \n ...                                          ...              ...   \n 2020-12-27 _automl_dummy_grain_col             2                4   \n 2020-12-28 _automl_dummy_grain_col             2                4   \n 2020-12-29 _automl_dummy_grain_col             2                4   \n 2020-12-30 _automl_dummy_grain_col             2                4   \n 2020-12-31 _automl_dummy_grain_col             2                4   \n \n                                     _automl_month  _automl_day  _automl_wday  \\\n date       _automl_dummy_grain_col                                             \n 2020-10-01 _automl_dummy_grain_col             10            1             3   \n 2020-10-02 _automl_dummy_grain_col             10            2             4   \n 2020-10-03 _automl_dummy_grain_col             10            3             5   \n 2020-10-04 _automl_dummy_grain_col             10            4             6   \n 2020-10-05 _automl_dummy_grain_col             10            5             0   \n ...                                           ...          ...           ...   \n 2020-12-27 _automl_dummy_grain_col             12           27             6   \n 2020-12-28 _automl_dummy_grain_col             12           28             0   \n 2020-12-29 _automl_dummy_grain_col             12           29             1   \n 2020-12-30 _automl_dummy_grain_col             12           30             2   \n 2020-12-31 _automl_dummy_grain_col             12           31             3   \n \n                                     _automl_qday  _automl_week  \\\n date       _automl_dummy_grain_col                               \n 2020-10-01 _automl_dummy_grain_col             1            40   \n 2020-10-02 _automl_dummy_grain_col             2            40   \n 2020-10-03 _automl_dummy_grain_col             3            40   \n 2020-10-04 _automl_dummy_grain_col             4            40   \n 2020-10-05 _automl_dummy_grain_col             5            41   \n ...                                          ...           ...   \n 2020-12-27 _automl_dummy_grain_col            88            52   \n 2020-12-28 _automl_dummy_grain_col            89            53   \n 2020-12-29 _automl_dummy_grain_col            90            53   \n 2020-12-30 _automl_dummy_grain_col            91            53   \n 2020-12-31 _automl_dummy_grain_col            92            53   \n \n                                     _automl_target_col  \n date       _automl_dummy_grain_col                      \n 2020-10-01 _automl_dummy_grain_col               41.60  \n 2020-10-02 _automl_dummy_grain_col               40.74  \n 2020-10-03 _automl_dummy_grain_col               40.55  \n 2020-10-04 _automl_dummy_grain_col               41.04  \n 2020-10-05 _automl_dummy_grain_col               41.85  \n ...                                                ...  \n 2020-12-27 _automl_dummy_grain_col               41.04  \n 2020-12-28 _automl_dummy_grain_col               41.85  \n 2020-12-29 _automl_dummy_grain_col               38.56  \n 2020-12-30 _automl_dummy_grain_col               41.42  \n 2020-12-31 _automl_dummy_grain_col               41.60  \n \n [92 rows x 10 columns])\n(array([41.59753086, 40.74111675, 40.5495283 , 41.03846154, 41.84827586,\n        38.55882353, 41.41666667, 41.59753086, 40.74111675, 40.5495283 ,\n        41.03846154, 41.84827586, 38.55882353, 41.41666667, 41.59753086,\n        40.74111675, 40.5495283 , 41.03846154, 41.84827586, 38.55882353,\n        41.41666667, 41.59753086, 40.74111675, 40.5495283 , 41.03846154,\n        41.84827586, 38.55882353, 41.41666667, 41.59753086, 40.74111675,\n        40.5495283 , 41.03846154, 41.84827586, 38.55882353, 41.41666667,\n        41.59753086, 40.74111675, 40.5495283 , 41.03846154, 41.84827586,\n        38.55882353, 41.41666667, 41.59753086, 40.74111675, 40.5495283 ,\n        41.03846154, 41.84827586, 38.55882353, 41.41666667, 41.59753086,\n        40.74111675, 40.5495283 , 41.03846154, 41.84827586, 38.55882353,\n        41.41666667, 41.59753086, 40.74111675, 40.5495283 , 41.03846154,\n        41.84827586, 38.55882353, 41.41666667, 41.59753086, 40.74111675,\n        40.5495283 , 41.03846154, 41.84827586, 38.55882353, 41.41666667,\n        41.59753086, 40.74111675, 40.5495283 , 41.03846154, 41.84827586,\n        38.55882353, 41.41666667, 41.59753086, 40.74111675, 40.5495283 ,\n        41.03846154, 41.84827586, 38.55882353, 41.41666667, 41.59753086,\n        40.74111675, 40.5495283 , 41.03846154, 41.84827586, 38.55882353,\n        41.41666667, 41.59753086]),\n                                     _automl_target_col_WASNULL  _automl_year  \\\n date       _automl_dummy_grain_col                                             \n 2020-10-01 _automl_dummy_grain_col                           0          2020   \n 2020-10-02 _automl_dummy_grain_col                           0          2020   \n 2020-10-03 _automl_dummy_grain_col                           0          2020   \n 2020-10-04 _automl_dummy_grain_col                           0          2020   \n 2020-10-05 _automl_dummy_grain_col                           0          2020   \n ...                                                        ...           ...   \n 2020-12-27 _automl_dummy_grain_col                           0          2020   \n 2020-12-28 _automl_dummy_grain_col                           0          2020   \n 2020-12-29 _automl_dummy_grain_col                           0          2020   \n 2020-12-30 _automl_dummy_grain_col                           0          2020   \n 2020-12-31 _automl_dummy_grain_col                           0          2020   \n \n                                     _automl_half  _automl_quarter  \\\n date       _automl_dummy_grain_col                                  \n 2020-10-01 _automl_dummy_grain_col             2                4   \n 2020-10-02 _automl_dummy_grain_col             2                4   \n 2020-10-03 _automl_dummy_grain_col             2                4   \n 2020-10-04 _automl_dummy_grain_col             2                4   \n 2020-10-05 _automl_dummy_grain_col             2                4   \n ...                                          ...              ...   \n 2020-12-27 _automl_dummy_grain_col             2                4   \n 2020-12-28 _automl_dummy_grain_col             2                4   \n 2020-12-29 _automl_dummy_grain_col             2                4   \n 2020-12-30 _automl_dummy_grain_col             2                4   \n 2020-12-31 _automl_dummy_grain_col             2                4   \n \n                                     _automl_month  _automl_day  _automl_wday  \\\n date       _automl_dummy_grain_col                                             \n 2020-10-01 _automl_dummy_grain_col             10            1             3   \n 2020-10-02 _automl_dummy_grain_col             10            2             4   \n 2020-10-03 _automl_dummy_grain_col             10            3             5   \n 2020-10-04 _automl_dummy_grain_col             10            4             6   \n 2020-10-05 _automl_dummy_grain_col             10            5             0   \n ...                                           ...          ...           ...   \n 2020-12-27 _automl_dummy_grain_col             12           27             6   \n 2020-12-28 _automl_dummy_grain_col             12           28             0   \n 2020-12-29 _automl_dummy_grain_col             12           29             1   \n 2020-12-30 _automl_dummy_grain_col             12           30             2   \n 2020-12-31 _automl_dummy_grain_col             12           31             3   \n \n                                     _automl_qday  _automl_week  \\\n date       _automl_dummy_grain_col                               \n 2020-10-01 _automl_dummy_grain_col             1            40   \n 2020-10-02 _automl_dummy_grain_col             2            40   \n 2020-10-03 _automl_dummy_grain_col             3            40   \n 2020-10-04 _automl_dummy_grain_col             4            40   \n 2020-10-05 _automl_dummy_grain_col             5            41   \n ...                                          ...           ...   \n 2020-12-27 _automl_dummy_grain_col            88            52   \n 2020-12-28 _automl_dummy_grain_col            89            53   \n 2020-12-29 _automl_dummy_grain_col            90            53   \n 2020-12-30 _automl_dummy_grain_col            91            53   \n 2020-12-31 _automl_dummy_grain_col            92            53   \n \n                                     _automl_target_col  \n date       _automl_dummy_grain_col                      \n 2020-10-01 _automl_dummy_grain_col               41.60  \n 2020-10-02 _automl_dummy_grain_col               40.74  \n 2020-10-03 _automl_dummy_grain_col               40.55  \n 2020-10-04 _automl_dummy_grain_col               41.04  \n 2020-10-05 _automl_dummy_grain_col               41.85  \n ...                                                ...  \n 2020-12-27 _automl_dummy_grain_col               41.04  \n 2020-12-28 _automl_dummy_grain_col               41.85  \n 2020-12-29 _automl_dummy_grain_col               38.56  \n 2020-12-30 _automl_dummy_grain_col               41.42  \n 2020-12-31 _automl_dummy_grain_col               41.60  \n \n [92 rows x 10 columns])"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "(array([41.59753086, 40.74111675, 40.5495283 , 41.03846154, 41.84827586,\n        38.55882353, 41.41666667, 41.59753086, 40.74111675, 40.5495283 ,\n        41.03846154, 41.84827586, 38.55882353, 41.41666667, 41.59753086,\n        40.74111675, 40.5495283 , 41.03846154, 41.84827586, 38.55882353,\n        41.41666667, 41.59753086, 40.74111675, 40.5495283 , 41.03846154,\n        41.84827586, 38.55882353, 41.41666667, 41.59753086, 40.74111675,\n        40.5495283 , 41.03846154, 41.84827586, 38.55882353, 41.41666667,\n        41.59753086, 40.74111675, 40.5495283 , 41.03846154, 41.84827586,\n        38.55882353, 41.41666667, 41.59753086, 40.74111675, 40.5495283 ,\n        41.03846154, 41.84827586, 38.55882353, 41.41666667, 41.59753086,\n        40.74111675, 40.5495283 , 41.03846154, 41.84827586, 38.55882353,\n        41.41666667, 41.59753086, 40.74111675, 40.5495283 , 41.03846154,\n        41.84827586, 38.55882353, 41.41666667, 41.59753086, 40.74111675,\n        40.5495283 , 41.03846154, 41.84827586, 38.55882353, 41.41666667,\n        41.59753086, 40.74111675, 40.5495283 , 41.03846154, 41.84827586,\n        38.55882353, 41.41666667, 41.59753086, 40.74111675, 40.5495283 ,\n        41.03846154, 41.84827586, 38.55882353, 41.41666667, 41.59753086,\n        40.74111675, 40.5495283 , 41.03846154, 41.84827586, 38.55882353,\n        41.41666667, 41.59753086]),\n                                     _automl_target_col_WASNULL  _automl_year  \\\n date       _automl_dummy_grain_col                                             \n 2020-10-01 _automl_dummy_grain_col                           0          2020   \n 2020-10-02 _automl_dummy_grain_col                           0          2020   \n 2020-10-03 _automl_dummy_grain_col                           0          2020   \n 2020-10-04 _automl_dummy_grain_col                           0          2020   \n 2020-10-05 _automl_dummy_grain_col                           0          2020   \n ...                                                        ...           ...   \n 2020-12-27 _automl_dummy_grain_col                           0          2020   \n 2020-12-28 _automl_dummy_grain_col                           0          2020   \n 2020-12-29 _automl_dummy_grain_col                           0          2020   \n 2020-12-30 _automl_dummy_grain_col                           0          2020   \n 2020-12-31 _automl_dummy_grain_col                           0          2020   \n \n                                     _automl_half  _automl_quarter  \\\n date       _automl_dummy_grain_col                                  \n 2020-10-01 _automl_dummy_grain_col             2                4   \n 2020-10-02 _automl_dummy_grain_col             2                4   \n 2020-10-03 _automl_dummy_grain_col             2                4   \n 2020-10-04 _automl_dummy_grain_col             2                4   \n 2020-10-05 _automl_dummy_grain_col             2                4   \n ...                                          ...              ...   \n 2020-12-27 _automl_dummy_grain_col             2                4   \n 2020-12-28 _automl_dummy_grain_col             2                4   \n 2020-12-29 _automl_dummy_grain_col             2                4   \n 2020-12-30 _automl_dummy_grain_col             2                4   \n 2020-12-31 _automl_dummy_grain_col             2                4   \n \n                                     _automl_month  _automl_day  _automl_wday  \\\n date       _automl_dummy_grain_col                                             \n 2020-10-01 _automl_dummy_grain_col             10            1             3   \n 2020-10-02 _automl_dummy_grain_col             10            2             4   \n 2020-10-03 _automl_dummy_grain_col             10            3             5   \n 2020-10-04 _automl_dummy_grain_col             10            4             6   \n 2020-10-05 _automl_dummy_grain_col             10            5             0   \n ...                                           ...          ...           ...   \n 2020-12-27 _automl_dummy_grain_col             12           27             6   \n 2020-12-28 _automl_dummy_grain_col             12           28             0   \n 2020-12-29 _automl_dummy_grain_col             12           29             1   \n 2020-12-30 _automl_dummy_grain_col             12           30             2   \n 2020-12-31 _automl_dummy_grain_col             12           31             3   \n \n                                     _automl_qday  _automl_week  \\\n date       _automl_dummy_grain_col                               \n 2020-10-01 _automl_dummy_grain_col             1            40   \n 2020-10-02 _automl_dummy_grain_col             2            40   \n 2020-10-03 _automl_dummy_grain_col             3            40   \n 2020-10-04 _automl_dummy_grain_col             4            40   \n 2020-10-05 _automl_dummy_grain_col             5            41   \n ...                                          ...           ...   \n 2020-12-27 _automl_dummy_grain_col            88            52   \n 2020-12-28 _automl_dummy_grain_col            89            53   \n 2020-12-29 _automl_dummy_grain_col            90            53   \n 2020-12-30 _automl_dummy_grain_col            91            53   \n 2020-12-31 _automl_dummy_grain_col            92            53   \n \n                                     _automl_target_col  \n date       _automl_dummy_grain_col                      \n 2020-10-01 _automl_dummy_grain_col               41.60  \n 2020-10-02 _automl_dummy_grain_col               40.74  \n 2020-10-03 _automl_dummy_grain_col               40.55  \n 2020-10-04 _automl_dummy_grain_col               41.04  \n 2020-10-05 _automl_dummy_grain_col               41.85  \n ...                                                ...  \n 2020-12-27 _automl_dummy_grain_col               41.04  \n 2020-12-28 _automl_dummy_grain_col               41.85  \n 2020-12-29 _automl_dummy_grain_col               38.56  \n 2020-12-30 _automl_dummy_grain_col               41.42  \n 2020-12-31 _automl_dummy_grain_col               41.60  \n \n [92 rows x 10 columns])"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "(array([39.50277501, 39.44715901, 39.49383374, 39.58764592, 39.62967161,\n        39.5886591 , 39.58191926, 39.5839655 , 39.5290955 , 39.56534011,\n        39.57522795, 39.68361674, 39.64012458, 39.65640139, 39.69760473,\n        39.74888407, 39.75531225, 39.75531225, 39.75799218, 39.74041153,\n        39.68696064, 39.73163377, 39.7608042 , 39.72160895, 39.84643256,\n        39.76739269, 39.71595438, 39.78547181, 40.08535402, 40.29676234,\n        40.35799691, 38.91534774, 38.7440626 , 38.75466041, 38.65130793,\n        38.66717056, 38.83854903, 38.77400059, 38.72276974, 38.76794473,\n        38.77854254, 38.64263648, 38.63699261, 38.70333745, 38.70333745,\n        38.72889023, 38.89086791, 38.90613519, 38.81560581, 38.8862595 ,\n        38.97043509, 38.9563225 , 38.96365927, 39.02230009, 39.06189335,\n        38.98099025, 38.93229951, 39.16980839, 39.34398352, 40.55680627,\n        40.47905207, 40.8755953 , 40.82140348, 40.74430117, 40.76312628,\n        40.9216368 , 40.95990889, 40.99870593, 40.99870593, 40.97829576,\n        40.96437986, 41.00416744, 40.99324311, 41.01095643, 40.85534076,\n        40.9177279 , 40.83374274, 40.85516403, 40.85679239, 40.79424424,\n        40.82097697, 40.79776425, 40.79776425, 40.76109773, 40.7188996 ,\n        40.76287552, 40.71480213, 40.69169302, 40.72455491, 40.59337536,\n        40.68954189, 40.68954189]),\n                                     _automl_target_col_WASNULL  _automl_year  \\\n date       _automl_dummy_grain_col                                             \n 2020-10-01 _automl_dummy_grain_col                           0          2020   \n 2020-10-02 _automl_dummy_grain_col                           0          2020   \n 2020-10-03 _automl_dummy_grain_col                           0          2020   \n 2020-10-04 _automl_dummy_grain_col                           0          2020   \n 2020-10-05 _automl_dummy_grain_col                           0          2020   \n ...                                                        ...           ...   \n 2020-12-27 _automl_dummy_grain_col                           0          2020   \n 2020-12-28 _automl_dummy_grain_col                           0          2020   \n 2020-12-29 _automl_dummy_grain_col                           0          2020   \n 2020-12-30 _automl_dummy_grain_col                           0          2020   \n 2020-12-31 _automl_dummy_grain_col                           0          2020   \n \n                                     _automl_half  _automl_quarter  \\\n date       _automl_dummy_grain_col                                  \n 2020-10-01 _automl_dummy_grain_col             2                4   \n 2020-10-02 _automl_dummy_grain_col             2                4   \n 2020-10-03 _automl_dummy_grain_col             2                4   \n 2020-10-04 _automl_dummy_grain_col             2                4   \n 2020-10-05 _automl_dummy_grain_col             2                4   \n ...                                          ...              ...   \n 2020-12-27 _automl_dummy_grain_col             2                4   \n 2020-12-28 _automl_dummy_grain_col             2                4   \n 2020-12-29 _automl_dummy_grain_col             2                4   \n 2020-12-30 _automl_dummy_grain_col             2                4   \n 2020-12-31 _automl_dummy_grain_col             2                4   \n \n                                     _automl_month  _automl_day  _automl_wday  \\\n date       _automl_dummy_grain_col                                             \n 2020-10-01 _automl_dummy_grain_col             10            1             3   \n 2020-10-02 _automl_dummy_grain_col             10            2             4   \n 2020-10-03 _automl_dummy_grain_col             10            3             5   \n 2020-10-04 _automl_dummy_grain_col             10            4             6   \n 2020-10-05 _automl_dummy_grain_col             10            5             0   \n ...                                           ...          ...           ...   \n 2020-12-27 _automl_dummy_grain_col             12           27             6   \n 2020-12-28 _automl_dummy_grain_col             12           28             0   \n 2020-12-29 _automl_dummy_grain_col             12           29             1   \n 2020-12-30 _automl_dummy_grain_col             12           30             2   \n 2020-12-31 _automl_dummy_grain_col             12           31             3   \n \n                                     _automl_qday  _automl_week  \\\n date       _automl_dummy_grain_col                               \n 2020-10-01 _automl_dummy_grain_col             1            40   \n 2020-10-02 _automl_dummy_grain_col             2            40   \n 2020-10-03 _automl_dummy_grain_col             3            40   \n 2020-10-04 _automl_dummy_grain_col             4            40   \n 2020-10-05 _automl_dummy_grain_col             5            41   \n ...                                          ...           ...   \n 2020-12-27 _automl_dummy_grain_col            88            52   \n 2020-12-28 _automl_dummy_grain_col            89            53   \n 2020-12-29 _automl_dummy_grain_col            90            53   \n 2020-12-30 _automl_dummy_grain_col            91            53   \n 2020-12-31 _automl_dummy_grain_col            92            53   \n \n                                     _automl_target_col  \n date       _automl_dummy_grain_col                      \n 2020-10-01 _automl_dummy_grain_col               39.50  \n 2020-10-02 _automl_dummy_grain_col               39.45  \n 2020-10-03 _automl_dummy_grain_col               39.49  \n 2020-10-04 _automl_dummy_grain_col               39.59  \n 2020-10-05 _automl_dummy_grain_col               39.63  \n ...                                                ...  \n 2020-12-27 _automl_dummy_grain_col               40.69  \n 2020-12-28 _automl_dummy_grain_col               40.72  \n 2020-12-29 _automl_dummy_grain_col               40.59  \n 2020-12-30 _automl_dummy_grain_col               40.69  \n 2020-12-31 _automl_dummy_grain_col               40.69  \n \n [92 rows x 10 columns])\n(array([41.59753086, 40.74111675, 40.5495283 , 41.03846154, 41.84827586,\n        38.55882353, 41.41666667, 41.59753086, 40.74111675, 40.5495283 ,\n        41.03846154, 41.84827586, 38.55882353, 41.41666667, 41.59753086,\n        40.74111675, 40.5495283 , 41.03846154, 41.84827586, 38.55882353,\n        41.41666667, 41.59753086, 40.74111675, 40.5495283 , 41.03846154,\n        41.84827586, 38.55882353, 41.41666667, 41.59753086, 40.74111675,\n        40.5495283 , 41.03846154, 41.84827586, 38.55882353, 41.41666667,\n        41.59753086, 40.74111675, 40.5495283 , 41.03846154, 41.84827586,\n        38.55882353, 41.41666667, 41.59753086, 40.74111675, 40.5495283 ,\n        41.03846154, 41.84827586, 38.55882353, 41.41666667, 41.59753086,\n        40.74111675, 40.5495283 , 41.03846154, 41.84827586, 38.55882353,\n        41.41666667, 41.59753086, 40.74111675, 40.5495283 , 41.03846154,\n        41.84827586, 38.55882353, 41.41666667, 41.59753086, 40.74111675,\n        40.5495283 , 41.03846154, 41.84827586, 38.55882353, 41.41666667,\n        41.59753086, 40.74111675, 40.5495283 , 41.03846154, 41.84827586,\n        38.55882353, 41.41666667, 41.59753086, 40.74111675, 40.5495283 ,\n        41.03846154, 41.84827586, 38.55882353, 41.41666667, 41.59753086,\n        40.74111675, 40.5495283 , 41.03846154, 41.84827586, 38.55882353,\n        41.41666667, 41.59753086]),\n                                     _automl_target_col_WASNULL  _automl_year  \\\n date       _automl_dummy_grain_col                                             \n 2020-10-01 _automl_dummy_grain_col                           0          2020   \n 2020-10-02 _automl_dummy_grain_col                           0          2020   \n 2020-10-03 _automl_dummy_grain_col                           0          2020   \n 2020-10-04 _automl_dummy_grain_col                           0          2020   \n 2020-10-05 _automl_dummy_grain_col                           0          2020   \n ...                                                        ...           ...   \n 2020-12-27 _automl_dummy_grain_col                           0          2020   \n 2020-12-28 _automl_dummy_grain_col                           0          2020   \n 2020-12-29 _automl_dummy_grain_col                           0          2020   \n 2020-12-30 _automl_dummy_grain_col                           0          2020   \n 2020-12-31 _automl_dummy_grain_col                           0          2020   \n \n                                     _automl_half  _automl_quarter  \\\n date       _automl_dummy_grain_col                                  \n 2020-10-01 _automl_dummy_grain_col             2                4   \n 2020-10-02 _automl_dummy_grain_col             2                4   \n 2020-10-03 _automl_dummy_grain_col             2                4   \n 2020-10-04 _automl_dummy_grain_col             2                4   \n 2020-10-05 _automl_dummy_grain_col             2                4   \n ...                                          ...              ...   \n 2020-12-27 _automl_dummy_grain_col             2                4   \n 2020-12-28 _automl_dummy_grain_col             2                4   \n 2020-12-29 _automl_dummy_grain_col             2                4   \n 2020-12-30 _automl_dummy_grain_col             2                4   \n 2020-12-31 _automl_dummy_grain_col             2                4   \n \n                                     _automl_month  _automl_day  _automl_wday  \\\n date       _automl_dummy_grain_col                                             \n 2020-10-01 _automl_dummy_grain_col             10            1             3   \n 2020-10-02 _automl_dummy_grain_col             10            2             4   \n 2020-10-03 _automl_dummy_grain_col             10            3             5   \n 2020-10-04 _automl_dummy_grain_col             10            4             6   \n 2020-10-05 _automl_dummy_grain_col             10            5             0   \n ...                                           ...          ...           ...   \n 2020-12-27 _automl_dummy_grain_col             12           27             6   \n 2020-12-28 _automl_dummy_grain_col             12           28             0   \n 2020-12-29 _automl_dummy_grain_col             12           29             1   \n 2020-12-30 _automl_dummy_grain_col             12           30             2   \n 2020-12-31 _automl_dummy_grain_col             12           31             3   \n \n                                     _automl_qday  _automl_week  \\\n date       _automl_dummy_grain_col                               \n 2020-10-01 _automl_dummy_grain_col             1            40   \n 2020-10-02 _automl_dummy_grain_col             2            40   \n 2020-10-03 _automl_dummy_grain_col             3            40   \n 2020-10-04 _automl_dummy_grain_col             4            40   \n 2020-10-05 _automl_dummy_grain_col             5            41   \n ...                                          ...           ...   \n 2020-12-27 _automl_dummy_grain_col            88            52   \n 2020-12-28 _automl_dummy_grain_col            89            53   \n 2020-12-29 _automl_dummy_grain_col            90            53   \n 2020-12-30 _automl_dummy_grain_col            91            53   \n 2020-12-31 _automl_dummy_grain_col            92            53   \n \n                                     _automl_target_col  \n date       _automl_dummy_grain_col                      \n 2020-10-01 _automl_dummy_grain_col               41.60  \n 2020-10-02 _automl_dummy_grain_col               40.74  \n 2020-10-03 _automl_dummy_grain_col               40.55  \n 2020-10-04 _automl_dummy_grain_col               41.04  \n 2020-10-05 _automl_dummy_grain_col               41.85  \n ...                                                ...  \n 2020-12-27 _automl_dummy_grain_col               41.04  \n 2020-12-28 _automl_dummy_grain_col               41.85  \n 2020-12-29 _automl_dummy_grain_col               38.56  \n 2020-12-30 _automl_dummy_grain_col               41.42  \n 2020-12-31 _automl_dummy_grain_col               41.60  \n \n [92 rows x 10 columns])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1680796037136
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_dfs = {}\n",
        "\n",
        "for city, predictions in all_predictions.items():\n",
        "    df = X_test_df.copy()\n",
        "    df['wait_time'] = predictions[0]\n",
        "    display(df)\n",
        "    predicted_dfs[city] = df"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "         date  wait_time\n0  2020-10-01      41.60\n1  2020-10-02      40.74\n2  2020-10-03      40.55\n3  2020-10-04      41.04\n4  2020-10-05      41.85\n..        ...        ...\n87 2020-12-27      41.04\n88 2020-12-28      41.85\n89 2020-12-29      38.56\n90 2020-12-30      41.42\n91 2020-12-31      41.60\n\n[92 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>wait_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-10-01</td>\n      <td>41.60</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-10-02</td>\n      <td>40.74</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-10-03</td>\n      <td>40.55</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-10-04</td>\n      <td>41.04</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-10-05</td>\n      <td>41.85</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>2020-12-27</td>\n      <td>41.04</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>2020-12-28</td>\n      <td>41.85</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>2020-12-29</td>\n      <td>38.56</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>2020-12-30</td>\n      <td>41.42</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>2020-12-31</td>\n      <td>41.60</td>\n    </tr>\n  </tbody>\n</table>\n<p>92 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "         date  wait_time\n0  2020-10-01      41.60\n1  2020-10-02      40.74\n2  2020-10-03      40.55\n3  2020-10-04      41.04\n4  2020-10-05      41.85\n..        ...        ...\n87 2020-12-27      41.04\n88 2020-12-28      41.85\n89 2020-12-29      38.56\n90 2020-12-30      41.42\n91 2020-12-31      41.60\n\n[92 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>wait_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-10-01</td>\n      <td>41.60</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-10-02</td>\n      <td>40.74</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-10-03</td>\n      <td>40.55</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-10-04</td>\n      <td>41.04</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-10-05</td>\n      <td>41.85</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>2020-12-27</td>\n      <td>41.04</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>2020-12-28</td>\n      <td>41.85</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>2020-12-29</td>\n      <td>38.56</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>2020-12-30</td>\n      <td>41.42</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>2020-12-31</td>\n      <td>41.60</td>\n    </tr>\n  </tbody>\n</table>\n<p>92 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "         date  wait_time\n0  2020-10-01      41.60\n1  2020-10-02      40.74\n2  2020-10-03      40.55\n3  2020-10-04      41.04\n4  2020-10-05      41.85\n..        ...        ...\n87 2020-12-27      41.04\n88 2020-12-28      41.85\n89 2020-12-29      38.56\n90 2020-12-30      41.42\n91 2020-12-31      41.60\n\n[92 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>wait_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-10-01</td>\n      <td>41.60</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-10-02</td>\n      <td>40.74</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-10-03</td>\n      <td>40.55</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-10-04</td>\n      <td>41.04</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-10-05</td>\n      <td>41.85</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>2020-12-27</td>\n      <td>41.04</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>2020-12-28</td>\n      <td>41.85</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>2020-12-29</td>\n      <td>38.56</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>2020-12-30</td>\n      <td>41.42</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>2020-12-31</td>\n      <td>41.60</td>\n    </tr>\n  </tbody>\n</table>\n<p>92 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "         date  wait_time\n0  2020-10-01      39.50\n1  2020-10-02      39.45\n2  2020-10-03      39.49\n3  2020-10-04      39.59\n4  2020-10-05      39.63\n..        ...        ...\n87 2020-12-27      40.69\n88 2020-12-28      40.72\n89 2020-12-29      40.59\n90 2020-12-30      40.69\n91 2020-12-31      40.69\n\n[92 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>wait_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-10-01</td>\n      <td>39.50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-10-02</td>\n      <td>39.45</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-10-03</td>\n      <td>39.49</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-10-04</td>\n      <td>39.59</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-10-05</td>\n      <td>39.63</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>2020-12-27</td>\n      <td>40.69</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>2020-12-28</td>\n      <td>40.72</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>2020-12-29</td>\n      <td>40.59</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>2020-12-30</td>\n      <td>40.69</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>2020-12-31</td>\n      <td>40.69</td>\n    </tr>\n  </tbody>\n</table>\n<p>92 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "         date  wait_time\n0  2020-10-01      41.60\n1  2020-10-02      40.74\n2  2020-10-03      40.55\n3  2020-10-04      41.04\n4  2020-10-05      41.85\n..        ...        ...\n87 2020-12-27      41.04\n88 2020-12-28      41.85\n89 2020-12-29      38.56\n90 2020-12-30      41.42\n91 2020-12-31      41.60\n\n[92 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>wait_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-10-01</td>\n      <td>41.60</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-10-02</td>\n      <td>40.74</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-10-03</td>\n      <td>40.55</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-10-04</td>\n      <td>41.04</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-10-05</td>\n      <td>41.85</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>2020-12-27</td>\n      <td>41.04</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>2020-12-28</td>\n      <td>41.85</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>2020-12-29</td>\n      <td>38.56</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>2020-12-30</td>\n      <td>41.42</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>2020-12-31</td>\n      <td>41.60</td>\n    </tr>\n  </tbody>\n</table>\n<p>92 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1680796054402
        },
        "scrolled": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Upload predictions to storage account"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "final_dfs = []\n",
        "\n",
        "for city, predicted_df in predicted_dfs.items():\n",
        "    print(city)\n",
        "    train_df = all_train_dfs[city]\n",
        "    final_df = pd.concat([train_df, predicted_df])\n",
        "    city_list = [city]*len(final_df)\n",
        "    final_df['city'] = city_list\n",
        "    display(final_df)\n",
        "    final_dfs.append(final_df)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Miami\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "           date  wait_time   city\n7238 2015-12-16      43.00  Miami\n7239 2015-12-17      42.11  Miami\n7240 2015-12-18      40.44  Miami\n7241 2015-12-19      41.05  Miami\n7242 2015-12-20      40.50  Miami\n...         ...        ...    ...\n87   2020-12-27      41.04  Miami\n88   2020-12-28      41.85  Miami\n89   2020-12-29      38.56  Miami\n90   2020-12-30      41.42  Miami\n91   2020-12-31      41.60  Miami\n\n[1843 rows x 3 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>wait_time</th>\n      <th>city</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7238</th>\n      <td>2015-12-16</td>\n      <td>43.00</td>\n      <td>Miami</td>\n    </tr>\n    <tr>\n      <th>7239</th>\n      <td>2015-12-17</td>\n      <td>42.11</td>\n      <td>Miami</td>\n    </tr>\n    <tr>\n      <th>7240</th>\n      <td>2015-12-18</td>\n      <td>40.44</td>\n      <td>Miami</td>\n    </tr>\n    <tr>\n      <th>7241</th>\n      <td>2015-12-19</td>\n      <td>41.05</td>\n      <td>Miami</td>\n    </tr>\n    <tr>\n      <th>7242</th>\n      <td>2015-12-20</td>\n      <td>40.50</td>\n      <td>Miami</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>2020-12-27</td>\n      <td>41.04</td>\n      <td>Miami</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>2020-12-28</td>\n      <td>41.85</td>\n      <td>Miami</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>2020-12-29</td>\n      <td>38.56</td>\n      <td>Miami</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>2020-12-30</td>\n      <td>41.42</td>\n      <td>Miami</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>2020-12-31</td>\n      <td>41.60</td>\n      <td>Miami</td>\n    </tr>\n  </tbody>\n</table>\n<p>1843 rows × 3 columns</p>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Los Angeles\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "           date  wait_time         city\n5428 2015-12-16      39.00  Los Angeles\n5429 2015-12-17      42.50  Los Angeles\n5430 2015-12-18      41.00  Los Angeles\n5431 2015-12-19      40.38  Los Angeles\n5432 2015-12-20      38.80  Los Angeles\n...         ...        ...          ...\n87   2020-12-27      41.04  Los Angeles\n88   2020-12-28      41.85  Los Angeles\n89   2020-12-29      38.56  Los Angeles\n90   2020-12-30      41.42  Los Angeles\n91   2020-12-31      41.60  Los Angeles\n\n[1843 rows x 3 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>wait_time</th>\n      <th>city</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5428</th>\n      <td>2015-12-16</td>\n      <td>39.00</td>\n      <td>Los Angeles</td>\n    </tr>\n    <tr>\n      <th>5429</th>\n      <td>2015-12-17</td>\n      <td>42.50</td>\n      <td>Los Angeles</td>\n    </tr>\n    <tr>\n      <th>5430</th>\n      <td>2015-12-18</td>\n      <td>41.00</td>\n      <td>Los Angeles</td>\n    </tr>\n    <tr>\n      <th>5431</th>\n      <td>2015-12-19</td>\n      <td>40.38</td>\n      <td>Los Angeles</td>\n    </tr>\n    <tr>\n      <th>5432</th>\n      <td>2015-12-20</td>\n      <td>38.80</td>\n      <td>Los Angeles</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>2020-12-27</td>\n      <td>41.04</td>\n      <td>Los Angeles</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>2020-12-28</td>\n      <td>41.85</td>\n      <td>Los Angeles</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>2020-12-29</td>\n      <td>38.56</td>\n      <td>Los Angeles</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>2020-12-30</td>\n      <td>41.42</td>\n      <td>Los Angeles</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>2020-12-31</td>\n      <td>41.60</td>\n      <td>Los Angeles</td>\n    </tr>\n  </tbody>\n</table>\n<p>1843 rows × 3 columns</p>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Honolulu\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "           date  wait_time      city\n3618 2015-12-16      36.00  Honolulu\n3619 2015-12-17      39.25  Honolulu\n3620 2015-12-18      45.00  Honolulu\n3621 2015-12-19      37.73  Honolulu\n3622 2015-12-20      40.67  Honolulu\n...         ...        ...       ...\n87   2020-12-27      41.04  Honolulu\n88   2020-12-28      41.85  Honolulu\n89   2020-12-29      38.56  Honolulu\n90   2020-12-30      41.42  Honolulu\n91   2020-12-31      41.60  Honolulu\n\n[1843 rows x 3 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>wait_time</th>\n      <th>city</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3618</th>\n      <td>2015-12-16</td>\n      <td>36.00</td>\n      <td>Honolulu</td>\n    </tr>\n    <tr>\n      <th>3619</th>\n      <td>2015-12-17</td>\n      <td>39.25</td>\n      <td>Honolulu</td>\n    </tr>\n    <tr>\n      <th>3620</th>\n      <td>2015-12-18</td>\n      <td>45.00</td>\n      <td>Honolulu</td>\n    </tr>\n    <tr>\n      <th>3621</th>\n      <td>2015-12-19</td>\n      <td>37.73</td>\n      <td>Honolulu</td>\n    </tr>\n    <tr>\n      <th>3622</th>\n      <td>2015-12-20</td>\n      <td>40.67</td>\n      <td>Honolulu</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>2020-12-27</td>\n      <td>41.04</td>\n      <td>Honolulu</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>2020-12-28</td>\n      <td>41.85</td>\n      <td>Honolulu</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>2020-12-29</td>\n      <td>38.56</td>\n      <td>Honolulu</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>2020-12-30</td>\n      <td>41.42</td>\n      <td>Honolulu</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>2020-12-31</td>\n      <td>41.60</td>\n      <td>Honolulu</td>\n    </tr>\n  </tbody>\n</table>\n<p>1843 rows × 3 columns</p>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Chicago\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "           date  wait_time     city\n1808 2015-12-16      45.33  Chicago\n1809 2015-12-17      41.33  Chicago\n1810 2015-12-18      42.75  Chicago\n1811 2015-12-19      42.07  Chicago\n1812 2015-12-20      42.62  Chicago\n...         ...        ...      ...\n87   2020-12-27      40.69  Chicago\n88   2020-12-28      40.72  Chicago\n89   2020-12-29      40.59  Chicago\n90   2020-12-30      40.69  Chicago\n91   2020-12-31      40.69  Chicago\n\n[1843 rows x 3 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>wait_time</th>\n      <th>city</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1808</th>\n      <td>2015-12-16</td>\n      <td>45.33</td>\n      <td>Chicago</td>\n    </tr>\n    <tr>\n      <th>1809</th>\n      <td>2015-12-17</td>\n      <td>41.33</td>\n      <td>Chicago</td>\n    </tr>\n    <tr>\n      <th>1810</th>\n      <td>2015-12-18</td>\n      <td>42.75</td>\n      <td>Chicago</td>\n    </tr>\n    <tr>\n      <th>1811</th>\n      <td>2015-12-19</td>\n      <td>42.07</td>\n      <td>Chicago</td>\n    </tr>\n    <tr>\n      <th>1812</th>\n      <td>2015-12-20</td>\n      <td>42.62</td>\n      <td>Chicago</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>2020-12-27</td>\n      <td>40.69</td>\n      <td>Chicago</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>2020-12-28</td>\n      <td>40.72</td>\n      <td>Chicago</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>2020-12-29</td>\n      <td>40.59</td>\n      <td>Chicago</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>2020-12-30</td>\n      <td>40.69</td>\n      <td>Chicago</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>2020-12-31</td>\n      <td>40.69</td>\n      <td>Chicago</td>\n    </tr>\n  </tbody>\n</table>\n<p>1843 rows × 3 columns</p>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Anchorage\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "         date  wait_time       city\n0  2015-12-17      37.00  Anchorage\n1  2015-12-18      46.50  Anchorage\n2  2015-12-19      41.67  Anchorage\n3  2015-12-20      39.00  Anchorage\n4  2015-12-21      43.00  Anchorage\n..        ...        ...        ...\n87 2020-12-27      41.04  Anchorage\n88 2020-12-28      41.85  Anchorage\n89 2020-12-29      38.56  Anchorage\n90 2020-12-30      41.42  Anchorage\n91 2020-12-31      41.60  Anchorage\n\n[1842 rows x 3 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>wait_time</th>\n      <th>city</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015-12-17</td>\n      <td>37.00</td>\n      <td>Anchorage</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015-12-18</td>\n      <td>46.50</td>\n      <td>Anchorage</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2015-12-19</td>\n      <td>41.67</td>\n      <td>Anchorage</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2015-12-20</td>\n      <td>39.00</td>\n      <td>Anchorage</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015-12-21</td>\n      <td>43.00</td>\n      <td>Anchorage</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>2020-12-27</td>\n      <td>41.04</td>\n      <td>Anchorage</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>2020-12-28</td>\n      <td>41.85</td>\n      <td>Anchorage</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>2020-12-29</td>\n      <td>38.56</td>\n      <td>Anchorage</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>2020-12-30</td>\n      <td>41.42</td>\n      <td>Anchorage</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>2020-12-31</td>\n      <td>41.60</td>\n      <td>Anchorage</td>\n    </tr>\n  </tbody>\n</table>\n<p>1842 rows × 3 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1680796063896
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_df = pd.concat(final_dfs)\n",
        "print(full_df.shape)\n",
        "full_df.to_csv(local_data_folder+'wait_time_forecasted.csv',index=False)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(9214, 3)\n"
        }
      ],
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1680796071739
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the data\n",
        "local_files = [local_data_folder + 'wait_time_forecasted.csv']\n",
        "print(local_files)\n",
        "\n",
        "dstore.upload_files(\n",
        "    files = local_files,\n",
        "    relative_root = local_data_folder,\n",
        "    target_path = '/',\n",
        "    overwrite=True,\n",
        "    show_progress=True\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['wait_time_data/wait_time_forecasted.csv']\nUploading an estimated of 1 files\nUploading wait_time_data/wait_time_forecasted.csv\nUploaded wait_time_data/wait_time_forecasted.csv, 1 files out of an estimated total of 1\nUploaded 1 files\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "$AZUREML_DATAREFERENCE_wait_time_prediction_store"
          },
          "metadata": {}
        }
      ],
      "execution_count": 36,
      "metadata": {
        "gather": {
          "logged": 1680796074433
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}